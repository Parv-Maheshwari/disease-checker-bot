{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GA Project -  disease-checking-bot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "e7ylma0t0hbi",
        "fV9lqo8Q2tyU"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm0Qfrod0qGe"
      },
      "source": [
        "### Google Drive Mount\n",
        "Code for mounting the google drive on the Colab Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shzwj36FMTO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa829adf-da56-48a3-f6ee-659a9d581dd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbYXou6chZf",
        "outputId": "4e8fc14f-0059-41e9-d882-37e4f1392183"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 16 17:25:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMHxPvYTAOvE",
        "outputId": "9a27a717-6c96-4bcd-eb0e-cd0f315d3c19"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eBLDSmCxAjZV",
        "outputId": "ca92eaf1-bdfa-4b70-b0f8-d542b1966a23"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Jab-WH1iyW"
      },
      "source": [
        "### Data Loading & Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOrQVxcXMSSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e777e1-9b3e-4443-b246-7cd4d31cab9c"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import np_utils\n",
        "\n",
        "# Select option for training RF/NB  OR ANN\n",
        "classifier_method = 'ANN'\n",
        "\n",
        "# Uncomment the relevatn Dataset\n",
        "# file_dir = 'gdrive/My Drive/IIT Bhilai Internship/Models/Symptom ID/'\n",
        "if(classifier_method=='RF/NB'):\n",
        "  file_dir = 'gdrive/My Drive/GA Project/Models/SymCat Random Forest Model/'\n",
        "if(classifier_method=='ANN'):\n",
        "  file_dir = 'gdrive/My Drive/GA Project/Models/ANN Classifier/'\n",
        "import os\n",
        "for dirname, _, filenames in os.walk(file_dir):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive/My Drive/GA Project/Models/ANN Classifier/Training_NN.csv\n",
            "gdrive/My Drive/GA Project/Models/ANN Classifier/Testing_NN.csv\n",
            "gdrive/My Drive/GA Project/Models/ANN Classifier/Testing.csv\n",
            "gdrive/My Drive/GA Project/Models/ANN Classifier/Training.csv\n",
            "gdrive/My Drive/GA Project/Models/ANN Classifier/data.csv\n",
            "gdrive/My Drive/GA Project/Models/ANN Classifier/model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FnZUV_SMSSY"
      },
      "source": [
        "# In case you want to use the prevalance of a symptom in the disease\n",
        "#   Uncoment the 'Training_Prob.csv' & 'Testing_Prob' lines & comment the other \n",
        "\n",
        "if(classifier_method=='RF/NB'):\n",
        "  df = pd.read_csv(file_dir + 'Training.csv')\n",
        "  df_test = pd.read_csv(file_dir + 'Testing.csv')\n",
        "\n",
        "if(classifier_method=='ANN'):\n",
        "#   df = pd.read_csv(file_dir + 'Training_NN.csv')\n",
        "  df = pd.read_csv(file_dir + 'data.csv')\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "  rows = len(df.index)\n",
        "  test_ratio =0.1\n",
        "  train_ratio = 1-test_ratio\n",
        "  df_train = df.iloc[:int(train_ratio*rows),:]\n",
        "  df_test = df.iloc[int(train_ratio*rows+1):,:]\n",
        "\n",
        "#   df_test = pd.read_csv(file_dir + 'Testing_NN.csv')\n",
        "\n",
        "# df = pd.read_csv(file_dir + 'Training_Prob.csv')\n",
        "# df_test = pd.read_csv(file_dir + 'Testing_Prob.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c25z52bTMSSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729e4308-6867-4e80-e136-7e7a8673d0f9"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "arn = pd.concat([df_train['prognosis'], df_test['prognosis']])\n",
        "le.fit(arn)\n",
        "print(len(le.classes_))\n",
        "\n",
        "x_train = df_train[df_train.columns.difference(['prognosis'])]\n",
        "y_train = le.fit_transform(df_train['prognosis'])\n",
        "\n",
        "x_test = df_test[df_test.columns.difference(['prognosis'])]\n",
        "y_test = le.fit_transform(df_test['prognosis'])\n",
        "# y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# print(type(x_train))\n",
        "# print(type(y_train))\n",
        "# y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0yMv4KFBZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23e2997-34af-46f2-9c6c-2b0339a9d471"
      },
      "source": [
        "df = pd.read_csv(file_dir + 'Training.csv')\n",
        "rows = len(df.index)\n",
        "test_ratio =0.1\n",
        "train_ratio = 1-test_ratio\n",
        "df_train = df.iloc[:int(train_ratio*rows),:]\n",
        "df_test = df.iloc[int(train_ratio*rows+1):,:]\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "arn = pd.concat([df_train['prognosis'], df_test['prognosis']])\n",
        "le.fit(arn)\n",
        "print(len(le.classes_))\n",
        "\n",
        "x_train = df_train[df_train.columns.difference(['prognosis'])]\n",
        "y_train = le.fit_transform(df_train['prognosis'])\n",
        "\n",
        "x_test = df_test[df_test.columns.difference(['prognosis'])]\n",
        "y_test = le.fit_transform(df_test['prognosis'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcnDhATKjAD5"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc-zfw0iHznU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d051d5-4428-477f-ce8b-ec3ce216ad12"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "symp_train_data = torch.tensor(x_train.values, dtype=torch.int64).to(device)\n",
        "train_outputs = torch.tensor(y_train).to(device)\n",
        "\n",
        "symp_test_data = torch.tensor(x_test.values, dtype=torch.int64).to(device)\n",
        "test_outputs = torch.tensor(y_test).to(device)\n",
        "\n",
        "print(symp_train_data.shape)\n",
        "print(train_outputs.shape)\n",
        "\n",
        "categorical_column_sizes = [2 for column in df.columns.difference(['prognosis'])]\n",
        "categorical_embedding_sizes = [(2, min(50, (2+1)//2)) for column in df.columns.difference(['prognosis'])]\n",
        "# print(symp_train_data.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8812, 144])\n",
            "torch.Size([8812])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dHKsKwHHznV"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, output_size, layers, p=0.4, weights = None):\n",
        "        super().__init__()\n",
        "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
        "        self.embedding_dropout = nn.Dropout(p)\n",
        "        # self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
        "\n",
        "        all_layers = []\n",
        "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
        "        input_size = num_categorical_cols\n",
        "\n",
        "        for i in layers:\n",
        "            all_layers.append(nn.Linear(input_size, i))\n",
        "            all_layers.append(nn.ReLU(inplace=True))\n",
        "            all_layers.append(nn.BatchNorm1d(i))\n",
        "            all_layers.append(nn.Dropout(p))\n",
        "            input_size = i\n",
        "\n",
        "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
        "\n",
        "        self.layers = nn.Sequential(*all_layers)\n",
        "        # self.weight = torch.nn.Parameter(torch.Tensor\n",
        "        if weights!= None:\n",
        "            for i in range(len(self.modules())):\n",
        "                (self.modules())[i].weight = weights[i]\n",
        "\n",
        "    def forward(self, x_categorical):\n",
        "        embeddings = []\n",
        "        for i,e in enumerate(self.all_embeddings):\n",
        "            embeddings.append(e(x_categorical[:,i]))\n",
        "        x = torch.cat(embeddings, 1)\n",
        "        x = self.embedding_dropout(x)\n",
        "\n",
        "        # x_numerical = self.batch_norm_num(x_numerical)\n",
        "        # x = torch.cat([x, x_numerical], 1)\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "# model = Model(categorical_embedding_sizes, 48, [200,100,50,25], p=0.4) # 48 = no. of diseases selected.\n",
        "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# model = MyRNN()\n",
        "\n",
        "\n",
        "# print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay88MCabHznY"
      },
      "source": [
        "# import wandb\n",
        "\n",
        "# # 1. Start a W&B run\n",
        "# wandb.init(project='hp3', entity='parv')\n",
        "model = Model(categorical_embedding_sizes, 48, [200], p=0.1).to(device) # 48 = no. of diseases selected.\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 150\n",
        "aggregated_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    y_pred = model(symp_train_data)\n",
        "    # print(y_pred.is_cuda)\n",
        "    single_loss = loss_function(y_pred,train_outputs)\n",
        "    # aggregated_losses.append(single_loss)\n",
        "\n",
        "    # if i%25 == 1:\n",
        "    # print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    single_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYBXoqg1DDnU"
      },
      "source": [
        "# Finding Target Variable\n",
        "with torch.no_grad():\n",
        "    # y_val = model(symp_train_data)\n",
        "    y_val = model(symp_test_data)\n",
        "\n",
        "    # loss = loss_function(y_val, train_outputs)\n",
        "    loss = loss_function(y_val, test_outputs)\n",
        "\n",
        "# print(f'Loss: {loss:.8f}')\n",
        "\n",
        "y_val = np.argmax(y_val.cpu(), axis=1)\n",
        "# print(y_val[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGXwhCV9hhQ"
      },
      "source": [
        "# plt.plot(range(epochs), aggregated_losses)\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('epoch');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAJRT5jTEPZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "077d171e-0704-4066-90e1-c807dc7ddcd0"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# print(test_outputs[:5])\n",
        "# print(y_val[:5])\n",
        "# print(confusion_matrix(test_outputs,y_val))\n",
        "# print(classification_report(test_outputs,y_val))\n",
        "#  print(accuracy_score(train_outputs, y_val))\n",
        "print(accuracy_score(test_outputs.cpu(), y_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8426966292134831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41qxFADACJps"
      },
      "source": [
        "# SAVING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkKe-ns_CKaM"
      },
      "source": [
        "torch.save(model,file_dir +'/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmFIqotwCwMs"
      },
      "source": [
        "# LOADING THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emu9fWHjCw0-"
      },
      "source": [
        "# Model class must be defined somewhere\n",
        "model = torch.load( file_dir +'/model.pt')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw01OryJEqu2"
      },
      "source": [
        "# GA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHRLQUAksfz6",
        "outputId": "17aa3568-7845-4e9e-e1c2-fdd4a3e7a7a1"
      },
      "source": [
        "symp_train_data = tf.convert_to_tensor(x_train.values, dtype=tf.int64)\n",
        "# symp_train_data = tf.constant([1,2,3,4,5])\n",
        "train_outputs =  tf.convert_to_tensor(y_train)\n",
        "\n",
        "symp_test_data =  tf.convert_to_tensor(x_test.values, dtype=tf.int64)\n",
        "test_outputs =  tf.convert_to_tensor(y_test)\n",
        "# print(symp_train_data.device)\n",
        "print(symp_train_data.shape)\n",
        "print(train_outputs.shape)\n",
        "\n",
        "categorical_column_sizes = [2 for column in df.columns.difference(['prognosis'])]\n",
        "categorical_embedding_sizes = [(2, min(50, (2+1)//2)) for column in df.columns.difference(['prognosis'])]\n",
        "# print(symp_train_data.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8769, 144)\n",
            "(8769,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mwg8IYwx_bF"
      },
      "source": [
        "import random\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bELmJjd2E7hs",
        "outputId": "3531bf4a-cce5-48e5-a1df-98ae36afeae4"
      },
      "source": [
        "!pip install pygad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/36/e36a9f2b4360d5464da73cea4886d3230878c9d7d2650907dc8ad4cb49cc/pygad-2.13.0-py3-none-any.whl (45kB)\n",
            "\r\u001b[K     |███████▏                        | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 40kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygad) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pygad) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pygad) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->pygad) (1.15.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-2.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "kDjSofyUdiS5",
        "outputId": "8e4068ca-ce41-4c91-b177-cd4a46ee6b6c"
      },
      "source": [
        "import numpy\n",
        "import pygad.nn\n",
        "\n",
        "# Reading the data features. Check the 'extract_features.py' script for extracting the features & preparing the outputs of the dataset.\n",
        "data_inputs = x_train.to_numpy() # Download from https://github.com/ahmedfgad/NumPyANN/blob/master/dataset_features.npy\n",
        "\n",
        "# # Optional step for filtering the features using the standard deviation.\n",
        "# features_STDs = numpy.std(a=data_inputs, axis=0)\n",
        "# data_inputs = data_inputs[:, features_STDs > 50]\n",
        "\n",
        "# Reading the data outputs. Check the 'extract_features.py' script for extracting the features & preparing the outputs of the dataset.\n",
        "data_outputs = y_train # Download from https://github.com/ahmedfgad/NumPyANN/blob/master/outputs.npy\n",
        "\n",
        "# The number of inputs (i.e. feature vector length) per sample\n",
        "num_inputs = data_inputs.shape[1]\n",
        "# Number of outputs per sample\n",
        "num_outputs = 48\n",
        "\n",
        "HL1_neurons = 250\n",
        "# HL2_neurons = 60\n",
        "\n",
        "# Building the network architecture.\n",
        "input_layer = pygad.nn.InputLayer(num_inputs)\n",
        "hidden_layer1 = pygad.nn.DenseLayer(num_neurons=HL1_neurons, previous_layer=input_layer, activation_function=\"relu\")\n",
        "# hidden_layer2 = pygad.nn.DenseLayer(num_neurons=HL2_neurons, previous_layer=hidden_layer1, activation_function=\"relu\")\n",
        "output_layer = pygad.nn.DenseLayer(num_neurons=num_outputs, previous_layer=hidden_layer1, activation_function=\"softmax\")\n",
        "\n",
        "# Training the network.\n",
        "pygad.nn.train(num_epochs=10,\n",
        "               last_layer=output_layer,\n",
        "               data_inputs=data_inputs,\n",
        "               data_outputs=data_outputs,\n",
        "               learning_rate=0.01)\n",
        "\n",
        "# Using the trained network for predictions.\n",
        "predictions = pygad.nn.predict(last_layer=output_layer, data_inputs=data_inputs)\n",
        "\n",
        "# Calculating some statistics\n",
        "# num_wrong = numpy.where(predictions != data_outputs)[0]\n",
        "# num_correct = data_outputs.size - num_wrong.size\n",
        "# accuracy = 100 * (num_correct/data_outputs.size)\n",
        "# predict_label =  pygad.nn.predict\n",
        "predict_label = np.argmax(predictions, axis=-1)\n",
        "ann.fitness = accuracy_score(train_outputs.cpu(), predict_label)\n",
        "print(\"Number of correct classifications : {num_correct}.\".format(num_correct=num_correct))\n",
        "print(\"Number of wrong classifications : {num_wrong}.\".format(num_wrong=num_wrong.size))\n",
        "print(\"Classification accuracy : {accuracy}.\".format(accuracy=accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n",
            "Epoch  1\n",
            "Epoch  2\n",
            "Epoch  3\n",
            "Epoch  4\n",
            "Epoch  5\n",
            "Epoch  6\n",
            "Epoch  7\n",
            "Epoch  8\n",
            "Epoch  9\n",
            "WARNING:tensorflow:From <ipython-input-14-4ec03e29e241>:44: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.identity instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4ec03e29e241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# predict_label =  pygad.nn.predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mpredict_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of correct classifications : {num_correct}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_correct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of wrong classifications : {num_wrong}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_wrong\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_wrong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 152\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array 380 cannot be considered a valid collection."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_ejHMz7PUKL4",
        "outputId": "3ee72f8a-4a4f-45c6-b969-f35c00ab42b2"
      },
      "source": [
        "import numpy\n",
        "import pygad\n",
        "import pygad.nn\n",
        "import pygad.gann\n",
        "\n",
        "def fitness_func(solution, sol_idx):\n",
        "    global GANN_instance, data_inputs, data_outputs\n",
        "\n",
        "    predictions = pygad.nn.predict(last_layer=GANN_instance.population_networks[sol_idx],\n",
        "                                   data_inputs=data_inputs)\n",
        "    predictions = np.array(predictions).reshape(data_inputs.shape[0] , 1)\n",
        "    # print(predictions.shape)\n",
        "\n",
        "    # print(predictions[0])\n",
        "    # print(data_outputs[0])\n",
        "    predict_label = np.argmax(predictions, axis=-1)\n",
        "    # print(predict_label.shape)\n",
        "\n",
        "    solution_fitness = accuracy_score(data_outputs, predict_label)*100\n",
        "    return solution_fitness\n",
        "\n",
        "def callback_generation(ga_instance):\n",
        "    global GANN_instance, last_fitness\n",
        "\n",
        "    population_matrices = pygad.gann.population_as_matrices(population_networks=GANN_instance.population_networks,\n",
        "                                                            population_vectors=ga_instance.population)\n",
        "\n",
        "    GANN_instance.update_population_trained_weights(population_trained_weights=population_matrices)\n",
        "\n",
        "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "    print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "    print(\"Change     = {change}\".format(change=ga_instance.best_solution()[1] - last_fitness))\n",
        "\n",
        "    last_fitness = ga_instance.best_solution()[1].copy()\n",
        "\n",
        "# Holds the fitness value of the previous generation.\n",
        "last_fitness = 0\n",
        "\n",
        "# Reading the input data.\n",
        "data_inputs = x_train.to_numpy() # Download from https://github.com/ahmedfgad/NumPyANN/blob/master/dataset_features.npy\n",
        "\n",
        "# Reading the output data.\n",
        "data_outputs = y_train # Download from https://github.com/ahmedfgad/NumPyANN/blob/master/outputs.npy\n",
        "\n",
        "# The length of the input vector for each sample (i.e. number of neurons in the input layer).\n",
        "num_inputs = data_inputs.shape[1]\n",
        "# The number of neurons in the output layer (i.e. number of classes).\n",
        "num_classes = 48\n",
        "\n",
        "# Creating an initial population of neural networks. The return of the initial_population() function holds references to the networks, not their weights. Using such references, the weights of all networks can be fetched.\n",
        "num_solutions = 20 # A solution or a network can be used interchangeably.\n",
        "GANN_instance = pygad.gann.GANN(num_solutions=num_solutions,\n",
        "                                num_neurons_input=num_inputs,\n",
        "                                num_neurons_hidden_layers=[200],\n",
        "                                num_neurons_output=num_classes,\n",
        "                                hidden_activations=[\"relu\"],\n",
        "                                output_activation=\"softmax\")\n",
        "\n",
        "# population does not hold the numerical weights of the network instead it holds a list of references to each last layer of each network (i.e. solution) in the population. A solution or a network can be used interchangeably.\n",
        "# If there is a population with 3 solutions (i.e. networks), then the population is a list with 3 elements. Each element is a reference to the last layer of each network. Using such a reference, all details of the network can be accessed.\n",
        "population_vectors = pygad.gann.population_as_vectors(population_networks=GANN_instance.population_networks)\n",
        "\n",
        "# To prepare the initial population, there are 2 ways:\n",
        "# 1) Prepare it yourself and pass it to the initial_population parameter. This way is useful when the user wants to start the genetic algorithm with a custom initial population.\n",
        "# 2) Assign valid integer values to the sol_per_pop and num_genes parameters. If the initial_population parameter exists, then the sol_per_pop and num_genes parameters are useless.\n",
        "initial_population = population_vectors.copy()\n",
        "\n",
        "num_parents_mating = 8 # Number of solutions to be selected as parents in the mating pool.\n",
        "\n",
        "num_generations = 50 # Number of generations.\n",
        "\n",
        "mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists.\n",
        "\n",
        "parent_selection_type = \"sss\" # Type of parent selection.\n",
        "\n",
        "crossover_type = \"scattered\" # Type of the crossover operator.\n",
        "\n",
        "mutation_type = \"random\" # Type of the mutation operator.\n",
        "\n",
        "keep_parents = -1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
        "\n",
        "ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                       num_parents_mating=num_parents_mating,\n",
        "                       initial_population=initial_population,\n",
        "                       fitness_func=fitness_func,\n",
        "                       mutation_percent_genes=mutation_percent_genes,\n",
        "                       parent_selection_type=parent_selection_type,\n",
        "                       crossover_type=crossover_type,\n",
        "                       crossover_probability = 0.9,\n",
        "                       mutation_type=mutation_type,\n",
        "                       keep_parents=keep_parents,\n",
        "                       on_generation=callback_generation)\n",
        "\n",
        "ga_instance.run()\n",
        "\n",
        "# After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
        "ga_instance.plot_result()\n",
        "\n",
        "# Returning the details of the best solution.\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
        "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
        "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
        "\n",
        "if ga_instance.best_solution_generation != -1:\n",
        "    print(\"Best fitness value reached after {best_solution_generation} generations.\".format(best_solution_generation=ga_instance.best_solution_generation))\n",
        "\n",
        "# Predicting the outputs of the data using the best solution.\n",
        "predictions = pygad.nn.predict(last_layer=GANN_instance.population_networks[solution_idx],\n",
        "                               data_inputs=data_inputs)\n",
        "print(\"Predictions of the trained network : {predictions}\".format(predictions=predictions))\n",
        "\n",
        "# Calculating some statistics\n",
        "# num_wrong = numpy.where(predictions != data_outputs)[0]\n",
        "# num_correct = data_outputs.size - num_wrong.size\n",
        "# accuracy = 100 * (num_correct/data_outputs.size)\n",
        "# print(\"Number of correct classifications : {num_correct}.\".format(num_correct=num_correct))\n",
        "# print(\"Number of wrong classifications : {num_wrong}.\".format(num_wrong=num_wrong.size))\n",
        "# print(\"Classification accuracy : {accuracy}.\".format(accuracy=accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8812, 144)\n",
            "Generation = 1\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 2.076713572401271\n",
            "Generation = 2\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 3\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 4\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 5\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 6\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 7\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 8\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 9\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 10\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 11\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 12\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 13\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 14\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 15\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 16\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 17\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 18\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 19\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 20\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 21\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 22\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 23\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 24\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 25\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 26\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 27\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 28\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 29\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 30\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 31\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 32\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 33\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 34\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 35\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 36\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 37\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 38\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 39\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 40\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 41\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 42\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 43\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 44\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 45\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 46\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 47\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 48\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 49\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n",
            "Generation = 50\n",
            "Fitness    = 2.076713572401271\n",
            "Change     = 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters of the best solution : [ 2.57085498 -0.01972712 -0.5189307  ... -4.81016531 -0.52108124\n",
            "  0.73242979]\n",
            "Fitness value of the best solution = 2.076713572401271\n",
            "Index of the best solution : 0\n",
            "Best fitness value reached after 0 generations.\n",
            "Predictions of the trained network : [14, 43, 43, 10, 37, 41, 4, 40, 16, 36, 22, 32, 43, 12, 0, 24, 36, 36, 42, 36, 43, 37, 14, 43, 0, 37, 47, 15, 40, 43, 41, 0, 14, 0, 4, 17, 18, 36, 47, 15, 7, 14, 22, 14, 38, 40, 43, 43, 13, 14, 30, 9, 43, 41, 36, 38, 43, 0, 18, 37, 0, 36, 24, 13, 40, 36, 13, 16, 40, 36, 43, 36, 14, 0, 0, 38, 36, 43, 4, 13, 36, 12, 24, 30, 43, 36, 31, 40, 11, 16, 15, 13, 0, 15, 43, 36, 0, 10, 43, 37, 29, 0, 36, 36, 12, 18, 43, 40, 25, 43, 40, 43, 30, 37, 13, 43, 0, 36, 15, 3, 36, 2, 36, 18, 42, 6, 37, 6, 0, 14, 33, 38, 36, 24, 47, 45, 0, 43, 40, 36, 15, 6, 24, 43, 14, 13, 36, 43, 0, 13, 42, 0, 43, 14, 37, 6, 40, 4, 5, 36, 21, 36, 24, 41, 16, 37, 24, 36, 41, 14, 43, 40, 15, 12, 36, 16, 38, 24, 18, 35, 36, 47, 43, 6, 12, 14, 18, 1, 0, 13, 15, 43, 40, 45, 35, 1, 38, 16, 15, 36, 13, 20, 0, 11, 0, 13, 45, 14, 24, 37, 22, 13, 38, 12, 13, 15, 47, 16, 0, 40, 0, 26, 36, 43, 0, 13, 29, 0, 13, 1, 13, 13, 43, 24, 36, 18, 43, 37, 5, 0, 37, 43, 14, 16, 36, 4, 40, 39, 40, 4, 36, 24, 24, 24, 12, 16, 37, 0, 14, 40, 43, 42, 16, 43, 4, 15, 24, 26, 37, 14, 15, 18, 37, 36, 40, 11, 40, 3, 42, 0, 19, 42, 15, 41, 13, 37, 43, 12, 22, 43, 0, 47, 17, 6, 31, 36, 22, 6, 37, 14, 0, 14, 0, 40, 14, 12, 37, 43, 24, 36, 36, 12, 24, 14, 43, 37, 43, 38, 18, 3, 37, 37, 36, 24, 37, 36, 4, 0, 47, 24, 43, 22, 0, 16, 36, 16, 4, 24, 22, 37, 16, 24, 40, 47, 43, 13, 36, 43, 33, 10, 37, 14, 36, 13, 4, 16, 6, 10, 43, 0, 42, 13, 35, 36, 12, 25, 41, 0, 43, 36, 16, 37, 36, 36, 14, 36, 36, 14, 40, 37, 47, 24, 14, 37, 43, 40, 0, 0, 43, 14, 43, 16, 45, 37, 36, 15, 2, 40, 43, 37, 43, 47, 43, 47, 13, 0, 14, 0, 24, 14, 18, 0, 36, 36, 16, 43, 18, 43, 12, 16, 18, 15, 14, 35, 0, 42, 37, 35, 12, 35, 26, 26, 43, 0, 14, 16, 0, 38, 40, 40, 20, 36, 36, 6, 46, 37, 20, 47, 6, 0, 43, 13, 4, 6, 25, 0, 37, 37, 36, 43, 13, 24, 4, 15, 36, 42, 43, 0, 6, 6, 37, 36, 16, 3, 24, 15, 0, 0, 47, 43, 35, 16, 42, 47, 16, 15, 14, 40, 37, 14, 4, 42, 41, 43, 19, 2, 36, 14, 0, 24, 45, 25, 38, 14, 17, 41, 16, 24, 43, 5, 37, 3, 11, 6, 36, 42, 24, 43, 13, 43, 12, 41, 0, 45, 16, 0, 43, 15, 35, 25, 43, 0, 40, 13, 25, 18, 15, 14, 41, 14, 20, 0, 0, 10, 4, 0, 13, 13, 16, 16, 37, 13, 36, 43, 22, 47, 43, 12, 14, 37, 25, 4, 33, 36, 13, 14, 43, 36, 41, 47, 40, 6, 16, 36, 0, 41, 24, 41, 40, 12, 19, 12, 10, 46, 0, 5, 0, 42, 40, 43, 36, 0, 0, 30, 43, 36, 7, 22, 35, 37, 36, 12, 25, 22, 37, 16, 18, 0, 46, 12, 11, 24, 36, 18, 36, 6, 18, 43, 37, 14, 36, 24, 18, 4, 7, 16, 9, 35, 43, 30, 31, 47, 26, 37, 11, 9, 0, 0, 18, 4, 36, 40, 14, 0, 37, 14, 0, 13, 42, 18, 13, 41, 40, 43, 43, 38, 0, 43, 32, 36, 12, 36, 43, 35, 37, 24, 36, 36, 18, 6, 14, 40, 43, 36, 36, 14, 13, 41, 13, 47, 39, 36, 42, 37, 35, 12, 38, 43, 11, 14, 0, 14, 16, 41, 42, 4, 40, 38, 37, 41, 13, 43, 37, 16, 0, 42, 36, 6, 16, 24, 35, 13, 16, 47, 13, 37, 37, 43, 36, 36, 6, 38, 0, 0, 13, 43, 15, 46, 43, 16, 40, 36, 11, 33, 13, 47, 19, 8, 24, 38, 14, 36, 14, 10, 37, 13, 37, 33, 36, 36, 35, 13, 18, 16, 37, 14, 41, 0, 29, 37, 13, 24, 38, 36, 12, 38, 28, 0, 6, 38, 38, 37, 26, 13, 38, 37, 36, 0, 36, 22, 41, 43, 22, 25, 9, 26, 15, 36, 13, 0, 38, 12, 15, 43, 36, 43, 11, 11, 18, 41, 7, 4, 40, 36, 35, 16, 30, 37, 40, 35, 4, 24, 37, 4, 43, 7, 16, 13, 43, 16, 40, 43, 40, 18, 6, 43, 36, 18, 47, 36, 0, 5, 24, 42, 0, 35, 36, 40, 24, 0, 1, 42, 11, 11, 16, 5, 45, 24, 40, 14, 24, 22, 12, 14, 14, 22, 40, 35, 43, 37, 37, 36, 0, 41, 36, 41, 41, 40, 0, 0, 11, 1, 12, 5, 36, 6, 36, 42, 12, 0, 45, 24, 47, 16, 42, 14, 14, 36, 9, 0, 0, 29, 36, 2, 36, 30, 13, 26, 11, 6, 10, 24, 11, 38, 24, 43, 1, 19, 36, 4, 37, 19, 18, 27, 7, 3, 14, 13, 37, 24, 36, 47, 43, 11, 43, 22, 15, 4, 41, 40, 43, 41, 22, 0, 18, 6, 37, 37, 0, 1, 16, 24, 40, 40, 47, 7, 16, 24, 37, 36, 6, 37, 36, 27, 36, 19, 43, 43, 19, 37, 4, 6, 36, 6, 36, 47, 36, 16, 43, 43, 5, 37, 37, 40, 43, 1, 10, 43, 0, 7, 24, 37, 36, 36, 6, 42, 37, 38, 13, 12, 0, 11, 43, 18, 16, 4, 14, 11, 24, 43, 0, 38, 6, 18, 4, 43, 5, 42, 24, 35, 43, 25, 16, 21, 16, 40, 4, 37, 18, 42, 18, 15, 24, 24, 33, 0, 12, 43, 14, 37, 36, 22, 0, 0, 13, 8, 37, 10, 36, 2, 41, 30, 47, 43, 6, 6, 40, 43, 43, 4, 43, 0, 12, 38, 13, 0, 0, 14, 18, 43, 42, 43, 37, 43, 40, 47, 2, 36, 10, 37, 16, 36, 14, 42, 11, 35, 41, 24, 0, 14, 10, 40, 15, 36, 43, 12, 16, 36, 18, 13, 36, 36, 47, 16, 43, 5, 36, 43, 14, 15, 43, 0, 0, 14, 36, 3, 43, 24, 43, 0, 37, 22, 36, 45, 43, 40, 37, 33, 30, 13, 43, 0, 42, 37, 1, 43, 36, 14, 43, 0, 25, 16, 43, 6, 12, 30, 41, 37, 37, 37, 40, 36, 43, 35, 28, 31, 36, 14, 15, 16, 43, 1, 24, 38, 43, 14, 24, 37, 16, 13, 14, 16, 16, 8, 35, 43, 47, 36, 16, 43, 36, 37, 27, 39, 40, 40, 36, 43, 35, 43, 16, 6, 36, 43, 25, 40, 18, 43, 6, 37, 43, 19, 15, 22, 13, 16, 43, 43, 47, 12, 13, 5, 40, 36, 38, 16, 14, 43, 12, 40, 41, 34, 24, 36, 11, 43, 43, 24, 6, 15, 13, 37, 6, 1, 0, 14, 36, 11, 22, 36, 11, 25, 36, 36, 40, 43, 16, 37, 22, 42, 37, 22, 37, 43, 11, 43, 0, 24, 18, 12, 46, 35, 37, 36, 35, 14, 40, 7, 47, 4, 15, 40, 43, 36, 43, 47, 15, 0, 22, 11, 38, 13, 41, 18, 24, 0, 43, 30, 43, 43, 6, 15, 43, 47, 43, 36, 0, 43, 18, 10, 36, 6, 26, 12, 7, 0, 12, 36, 43, 47, 45, 24, 37, 13, 40, 36, 45, 10, 41, 0, 3, 36, 37, 37, 40, 24, 35, 43, 36, 40, 7, 45, 37, 36, 36, 43, 0, 16, 10, 36, 40, 15, 43, 16, 36, 0, 0, 22, 43, 14, 11, 40, 43, 22, 43, 47, 34, 0, 12, 43, 31, 37, 0, 36, 36, 35, 13, 13, 47, 4, 47, 0, 43, 43, 21, 24, 0, 0, 43, 16, 40, 4, 15, 42, 42, 36, 6, 1, 36, 47, 18, 15, 16, 37, 0, 12, 0, 36, 13, 16, 6, 13, 47, 5, 0, 40, 16, 43, 16, 37, 24, 22, 27, 37, 43, 36, 15, 0, 16, 41, 37, 16, 38, 24, 5, 22, 13, 14, 36, 16, 43, 43, 24, 37, 12, 12, 24, 22, 40, 0, 36, 12, 2, 13, 47, 6, 6, 14, 16, 16, 30, 36, 43, 38, 38, 18, 47, 40, 42, 14, 35, 43, 15, 37, 35, 36, 16, 36, 37, 39, 6, 46, 40, 14, 36, 11, 36, 33, 13, 0, 13, 36, 41, 4, 34, 3, 43, 24, 40, 47, 36, 12, 37, 36, 37, 36, 24, 13, 43, 16, 19, 36, 4, 19, 18, 40, 38, 12, 24, 22, 20, 0, 13, 36, 37, 30, 43, 37, 36, 15, 41, 12, 4, 0, 16, 37, 19, 43, 33, 43, 40, 16, 43, 14, 42, 36, 36, 18, 15, 20, 43, 43, 12, 40, 36, 19, 14, 43, 0, 47, 43, 24, 20, 37, 38, 0, 43, 24, 14, 22, 13, 14, 36, 43, 46, 0, 40, 42, 19, 18, 43, 18, 4, 43, 38, 0, 0, 36, 20, 24, 4, 14, 24, 41, 24, 13, 36, 36, 40, 13, 14, 6, 36, 18, 37, 1, 0, 43, 22, 36, 43, 35, 36, 20, 37, 25, 0, 47, 42, 42, 22, 0, 28, 31, 43, 41, 14, 39, 30, 24, 37, 16, 36, 40, 4, 21, 18, 43, 14, 40, 33, 0, 32, 0, 7, 0, 12, 12, 14, 16, 38, 47, 43, 0, 0, 41, 13, 6, 24, 47, 36, 43, 16, 13, 36, 37, 28, 39, 36, 0, 20, 0, 10, 47, 14, 0, 0, 11, 43, 18, 11, 43, 13, 36, 31, 13, 16, 38, 38, 11, 43, 33, 37, 20, 13, 36, 40, 36, 43, 16, 43, 43, 41, 20, 43, 14, 11, 43, 47, 15, 37, 47, 37, 37, 41, 36, 35, 37, 46, 42, 34, 1, 16, 36, 36, 37, 0, 10, 24, 12, 12, 37, 40, 43, 40, 46, 42, 43, 36, 30, 36, 16, 43, 13, 18, 36, 14, 36, 43, 37, 12, 22, 42, 47, 24, 24, 12, 47, 10, 13, 6, 43, 36, 2, 37, 36, 13, 13, 13, 40, 43, 43, 37, 36, 14, 37, 37, 16, 6, 47, 40, 37, 37, 0, 4, 40, 22, 36, 0, 36, 11, 12, 14, 11, 40, 40, 16, 0, 13, 0, 15, 22, 36, 27, 12, 36, 12, 26, 0, 12, 35, 36, 0, 0, 20, 42, 22, 43, 12, 4, 31, 43, 18, 12, 12, 15, 43, 5, 0, 43, 30, 24, 18, 6, 15, 5, 13, 35, 0, 36, 0, 9, 36, 41, 47, 13, 12, 36, 12, 20, 43, 43, 36, 36, 36, 12, 15, 43, 43, 43, 14, 45, 16, 41, 14, 43, 0, 0, 40, 16, 47, 6, 36, 37, 13, 15, 42, 18, 14, 12, 37, 36, 43, 33, 13, 13, 40, 37, 12, 5, 43, 35, 47, 40, 43, 42, 43, 0, 43, 36, 13, 30, 14, 43, 40, 14, 5, 36, 15, 43, 37, 37, 26, 10, 16, 16, 0, 14, 37, 14, 13, 0, 14, 36, 36, 22, 43, 36, 6, 14, 40, 47, 36, 43, 9, 40, 42, 4, 47, 16, 0, 1, 33, 24, 0, 14, 42, 14, 21, 36, 40, 38, 43, 25, 0, 14, 3, 43, 0, 43, 11, 4, 4, 24, 27, 0, 3, 0, 36, 43, 43, 43, 46, 4, 14, 43, 24, 26, 37, 24, 24, 6, 6, 22, 36, 43, 3, 14, 37, 43, 38, 9, 36, 16, 42, 6, 6, 43, 36, 43, 40, 4, 40, 37, 37, 15, 40, 24, 14, 14, 40, 36, 36, 40, 43, 24, 45, 43, 37, 16, 6, 40, 4, 3, 36, 25, 4, 40, 12, 1, 7, 43, 31, 43, 10, 12, 40, 2, 35, 37, 37, 37, 36, 37, 0, 36, 24, 14, 43, 43, 43, 6, 13, 47, 43, 13, 4, 36, 14, 13, 19, 36, 11, 40, 15, 6, 40, 10, 4, 15, 40, 16, 6, 16, 14, 16, 30, 42, 5, 14, 45, 37, 0, 0, 6, 24, 43, 24, 36, 40, 15, 41, 12, 12, 6, 34, 4, 18, 25, 36, 22, 12, 24, 43, 43, 18, 35, 43, 20, 24, 37, 37, 42, 15, 0, 16, 15, 40, 36, 36, 13, 18, 36, 4, 3, 37, 18, 43, 36, 43, 47, 14, 47, 40, 43, 37, 40, 36, 47, 40, 13, 43, 0, 43, 24, 16, 37, 40, 36, 3, 7, 22, 18, 16, 10, 42, 36, 35, 36, 18, 16, 42, 36, 37, 2, 2, 13, 36, 42, 37, 14, 47, 26, 30, 42, 47, 0, 13, 14, 43, 33, 37, 41, 40, 37, 43, 43, 13, 4, 47, 16, 42, 14, 24, 14, 36, 42, 36, 43, 0, 40, 0, 18, 24, 37, 43, 24, 37, 40, 12, 12, 18, 0, 14, 43, 4, 13, 31, 40, 37, 43, 11, 16, 47, 37, 36, 30, 3, 40, 14, 3, 15, 24, 43, 37, 0, 0, 37, 25, 31, 36, 12, 20, 36, 47, 0, 43, 24, 42, 10, 4, 22, 21, 18, 41, 43, 24, 12, 13, 26, 4, 32, 36, 0, 12, 19, 2, 6, 43, 47, 42, 14, 47, 41, 36, 14, 14, 37, 18, 24, 41, 43, 42, 20, 4, 40, 14, 21, 4, 43, 10, 39, 36, 37, 12, 36, 36, 24, 14, 45, 36, 43, 16, 6, 18, 38, 25, 36, 0, 16, 41, 43, 14, 40, 12, 13, 38, 16, 22, 36, 41, 13, 24, 20, 13, 39, 4, 43, 42, 41, 10, 24, 13, 14, 47, 47, 24, 38, 24, 11, 16, 4, 37, 43, 6, 37, 19, 16, 14, 13, 16, 43, 11, 35, 12, 2, 37, 14, 43, 6, 47, 16, 41, 16, 36, 41, 0, 46, 43, 41, 0, 43, 37, 43, 36, 43, 11, 6, 19, 12, 25, 20, 2, 16, 38, 0, 41, 0, 12, 37, 19, 14, 18, 36, 47, 24, 6, 24, 41, 45, 24, 6, 12, 16, 37, 42, 19, 43, 35, 36, 37, 3, 14, 14, 43, 43, 42, 41, 47, 6, 43, 14, 36, 0, 36, 6, 38, 43, 43, 19, 24, 43, 39, 40, 40, 47, 35, 37, 15, 13, 14, 21, 40, 24, 41, 37, 12, 41, 41, 43, 36, 16, 43, 38, 0, 3, 41, 16, 33, 12, 24, 0, 37, 6, 40, 12, 37, 43, 11, 47, 0, 14, 0, 20, 42, 40, 47, 39, 43, 37, 10, 13, 16, 37, 24, 43, 24, 18, 32, 14, 43, 20, 33, 28, 42, 0, 37, 11, 0, 36, 3, 24, 14, 41, 7, 41, 42, 41, 36, 38, 37, 43, 11, 13, 36, 40, 37, 4, 43, 47, 43, 6, 5, 36, 41, 33, 35, 36, 41, 20, 2, 10, 10, 19, 14, 45, 9, 0, 16, 43, 35, 40, 43, 28, 11, 42, 41, 47, 47, 14, 37, 41, 40, 16, 43, 16, 43, 36, 3, 36, 19, 37, 14, 39, 13, 6, 37, 43, 0, 37, 43, 36, 40, 7, 11, 11, 24, 20, 43, 43, 0, 41, 0, 22, 11, 36, 24, 4, 33, 14, 36, 6, 15, 43, 37, 12, 37, 36, 16, 13, 15, 0, 22, 43, 36, 43, 36, 13, 0, 36, 37, 40, 14, 4, 6, 41, 37, 40, 36, 24, 37, 0, 47, 20, 35, 24, 40, 47, 43, 37, 13, 43, 36, 41, 14, 18, 43, 12, 47, 7, 26, 10, 14, 36, 36, 40, 36, 36, 37, 16, 43, 18, 36, 43, 3, 12, 40, 43, 14, 43, 0, 15, 18, 3, 37, 38, 36, 43, 43, 41, 43, 15, 40, 16, 17, 10, 14, 43, 22, 15, 43, 10, 24, 47, 47, 35, 42, 37, 43, 26, 36, 12, 42, 38, 36, 46, 40, 36, 13, 29, 41, 24, 43, 16, 0, 47, 15, 14, 30, 15, 41, 28, 40, 15, 37, 3, 41, 47, 41, 43, 38, 4, 47, 36, 43, 36, 37, 41, 14, 10, 47, 36, 38, 40, 35, 15, 0, 37, 6, 15, 16, 37, 0, 43, 14, 13, 36, 13, 0, 47, 26, 40, 10, 43, 4, 14, 36, 12, 38, 46, 13, 47, 11, 41, 43, 36, 37, 36, 37, 43, 15, 0, 1, 7, 36, 36, 24, 14, 12, 5, 43, 43, 13, 1, 22, 0, 36, 1, 4, 16, 37, 14, 47, 43, 41, 36, 15, 33, 47, 41, 9, 43, 15, 24, 4, 3, 6, 13, 43, 14, 37, 0, 13, 18, 14, 43, 15, 31, 0, 13, 0, 13, 43, 0, 43, 41, 15, 41, 41, 36, 28, 43, 35, 43, 42, 38, 14, 13, 8, 41, 4, 13, 14, 47, 30, 40, 41, 0, 0, 43, 0, 14, 37, 10, 11, 0, 47, 43, 16, 15, 24, 36, 16, 37, 37, 47, 43, 36, 36, 13, 16, 24, 36, 22, 37, 42, 0, 18, 12, 38, 37, 2, 40, 0, 20, 0, 37, 43, 15, 38, 18, 36, 25, 40, 43, 16, 47, 40, 37, 14, 36, 36, 16, 24, 46, 26, 37, 27, 6, 43, 16, 24, 36, 41, 47, 11, 24, 4, 30, 43, 33, 22, 18, 24, 47, 0, 42, 47, 24, 14, 36, 1, 43, 33, 11, 45, 43, 43, 11, 46, 11, 16, 40, 18, 37, 16, 35, 36, 36, 43, 43, 16, 15, 24, 15, 13, 30, 4, 37, 37, 42, 36, 40, 37, 37, 37, 10, 38, 37, 38, 9, 24, 19, 42, 38, 25, 9, 15, 33, 47, 36, 13, 37, 24, 46, 7, 37, 40, 43, 24, 24, 13, 18, 40, 36, 2, 22, 36, 26, 13, 11, 41, 24, 47, 38, 14, 43, 14, 6, 40, 14, 41, 43, 7, 0, 36, 37, 22, 36, 25, 24, 4, 10, 35, 18, 36, 37, 24, 36, 43, 43, 22, 41, 0, 16, 6, 0, 38, 43, 16, 0, 12, 0, 40, 36, 37, 16, 0, 10, 24, 47, 22, 36, 14, 0, 6, 43, 36, 36, 14, 43, 16, 36, 37, 24, 20, 41, 47, 45, 13, 24, 0, 16, 35, 12, 15, 36, 5, 16, 15, 0, 42, 38, 37, 31, 15, 41, 42, 37, 13, 37, 43, 36, 24, 40, 37, 37, 36, 37, 13, 36, 43, 37, 40, 40, 37, 12, 24, 30, 35, 11, 36, 43, 36, 1, 0, 35, 18, 12, 11, 12, 42, 37, 35, 6, 41, 0, 43, 14, 36, 46, 36, 37, 47, 13, 12, 39, 14, 14, 43, 36, 13, 40, 43, 18, 43, 43, 13, 37, 37, 17, 41, 19, 0, 47, 43, 21, 37, 24, 37, 6, 42, 13, 13, 40, 5, 47, 11, 16, 20, 4, 41, 24, 12, 42, 5, 12, 0, 43, 1, 43, 14, 15, 36, 36, 14, 24, 27, 42, 38, 40, 40, 12, 40, 22, 14, 12, 40, 37, 43, 47, 43, 42, 4, 0, 24, 37, 14, 37, 38, 16, 14, 45, 3, 36, 16, 16, 20, 12, 43, 22, 36, 31, 41, 35, 24, 28, 41, 24, 4, 0, 41, 46, 36, 37, 22, 14, 15, 24, 14, 14, 3, 47, 36, 33, 9, 33, 40, 28, 14, 14, 40, 11, 0, 13, 14, 24, 43, 40, 0, 37, 24, 0, 43, 4, 30, 24, 0, 36, 36, 13, 43, 37, 13, 13, 13, 47, 43, 36, 35, 43, 36, 36, 37, 36, 37, 36, 43, 0, 36, 0, 43, 16, 36, 43, 47, 47, 15, 47, 0, 40, 36, 14, 42, 12, 37, 35, 12, 16, 35, 13, 12, 36, 4, 40, 37, 37, 37, 37, 43, 41, 38, 43, 36, 18, 46, 4, 10, 22, 24, 43, 7, 19, 25, 40, 14, 0, 27, 16, 46, 18, 22, 16, 6, 43, 12, 10, 15, 14, 43, 40, 12, 24, 4, 14, 43, 14, 14, 20, 13, 36, 13, 43, 43, 18, 24, 43, 5, 15, 43, 2, 41, 33, 47, 43, 40, 16, 18, 40, 7, 47, 27, 14, 20, 0, 37, 14, 37, 37, 13, 10, 22, 0, 20, 16, 0, 41, 15, 22, 10, 0, 37, 37, 31, 4, 38, 36, 9, 24, 42, 41, 36, 19, 36, 36, 22, 43, 37, 6, 0, 36, 43, 14, 13, 4, 43, 40, 13, 11, 15, 17, 3, 12, 36, 43, 5, 16, 36, 15, 13, 25, 36, 36, 12, 47, 11, 0, 36, 9, 10, 13, 35, 14, 15, 40, 11, 11, 36, 14, 22, 36, 19, 43, 43, 0, 9, 0, 35, 14, 19, 47, 14, 38, 12, 43, 29, 40, 25, 36, 13, 43, 43, 7, 36, 37, 45, 27, 31, 7, 15, 36, 43, 47, 16, 47, 43, 22, 37, 4, 37, 35, 43, 43, 37, 24, 22, 13, 35, 42, 36, 9, 37, 12, 41, 37, 0, 46, 37, 14, 43, 14, 43, 25, 40, 15, 10, 0, 41, 43, 37, 43, 14, 30, 6, 40, 3, 15, 13, 36, 16, 36, 14, 47, 15, 36, 35, 38, 22, 0, 5, 20, 37, 0, 1, 0, 14, 43, 5, 18, 18, 13, 13, 30, 0, 37, 28, 43, 43, 37, 13, 16, 35, 43, 47, 15, 16, 15, 30, 4, 41, 16, 3, 36, 11, 43, 47, 13, 6, 24, 6, 14, 15, 24, 37, 14, 0, 41, 12, 13, 12, 32, 24, 24, 40, 35, 16, 7, 40, 43, 13, 13, 0, 43, 41, 43, 24, 47, 37, 0, 21, 40, 31, 3, 24, 18, 11, 12, 36, 14, 13, 8, 37, 6, 43, 43, 36, 0, 0, 41, 47, 37, 10, 43, 43, 14, 0, 24, 43, 43, 11, 36, 0, 4, 0, 15, 0, 40, 43, 22, 4, 36, 47, 40, 43, 46, 6, 6, 37, 14, 36, 38, 41, 40, 15, 6, 36, 0, 36, 36, 14, 1, 40, 43, 40, 36, 47, 17, 13, 43, 37, 14, 41, 26, 22, 43, 40, 23, 43, 16, 45, 37, 18, 40, 13, 35, 14, 32, 35, 36, 10, 3, 36, 43, 11, 13, 36, 25, 11, 0, 12, 40, 11, 43, 14, 0, 40, 36, 37, 10, 0, 36, 0, 14, 40, 43, 42, 40, 47, 36, 43, 30, 24, 9, 43, 47, 10, 45, 10, 36, 46, 36, 0, 13, 37, 4, 6, 37, 18, 2, 43, 38, 15, 13, 28, 40, 43, 40, 43, 40, 16, 35, 10, 36, 35, 3, 15, 16, 43, 43, 0, 36, 47, 16, 13, 9, 9, 4, 40, 6, 0, 43, 16, 25, 43, 36, 36, 35, 15, 36, 14, 0, 42, 24, 3, 24, 16, 45, 0, 13, 36, 0, 11, 40, 37, 36, 36, 42, 14, 35, 13, 16, 13, 43, 43, 24, 37, 11, 16, 14, 16, 40, 24, 35, 42, 43, 37, 22, 0, 0, 22, 36, 40, 47, 14, 35, 36, 36, 35, 34, 14, 36, 39, 37, 36, 14, 16, 22, 11, 35, 35, 13, 14, 43, 4, 40, 41, 24, 13, 0, 26, 41, 3, 22, 12, 10, 37, 12, 22, 21, 35, 33, 43, 43, 42, 0, 47, 18, 36, 37, 16, 46, 43, 40, 39, 14, 42, 26, 13, 28, 37, 37, 21, 16, 41, 37, 35, 43, 18, 36, 13, 16, 43, 12, 36, 47, 47, 43, 0, 35, 37, 6, 13, 35, 47, 10, 1, 19, 14, 47, 43, 10, 24, 43, 22, 9, 22, 42, 5, 18, 37, 41, 6, 40, 16, 12, 0, 37, 24, 43, 20, 14, 47, 10, 37, 36, 11, 20, 15, 37, 13, 38, 10, 13, 5, 37, 0, 37, 4, 38, 40, 35, 24, 1, 11, 37, 22, 5, 16, 39, 24, 14, 13, 22, 10, 36, 40, 39, 41, 16, 24, 47, 35, 40, 43, 38, 40, 14, 22, 37, 0, 37, 25, 24, 47, 43, 36, 4, 43, 47, 43, 36, 40, 14, 43, 24, 43, 47, 42, 42, 31, 36, 23, 15, 15, 9, 47, 40, 37, 35, 13, 13, 1, 6, 29, 14, 43, 22, 4, 40, 42, 37, 12, 41, 18, 36, 36, 37, 39, 11, 29, 36, 0, 14, 24, 43, 35, 42, 16, 35, 36, 42, 40, 36, 13, 43, 0, 24, 36, 20, 25, 14, 6, 38, 13, 16, 36, 22, 13, 0, 35, 9, 43, 37, 0, 36, 15, 13, 41, 36, 43, 4, 43, 42, 22, 24, 16, 24, 4, 24, 16, 43, 16, 15, 24, 16, 47, 36, 37, 3, 4, 16, 43, 15, 37, 33, 12, 35, 37, 36, 32, 6, 43, 47, 4, 4, 12, 3, 7, 4, 0, 4, 37, 24, 37, 36, 0, 11, 33, 35, 3, 20, 40, 37, 6, 43, 6, 41, 47, 37, 22, 3, 6, 13, 16, 2, 36, 36, 15, 36, 42, 0, 43, 0, 42, 47, 2, 37, 41, 13, 43, 11, 20, 11, 13, 47, 36, 12, 16, 36, 22, 12, 41, 40, 12, 16, 40, 0, 43, 43, 36, 47, 43, 47, 19, 24, 36, 37, 40, 41, 14, 47, 37, 43, 22, 43, 3, 15, 41, 35, 36, 41, 41, 14, 6, 6, 16, 16, 24, 16, 0, 36, 37, 15, 47, 15, 20, 38, 13, 35, 18, 0, 14, 38, 14, 15, 43, 40, 20, 36, 33, 24, 6, 18, 36, 42, 36, 40, 37, 0, 7, 40, 13, 0, 6, 13, 14, 24, 13, 36, 26, 6, 3, 14, 14, 33, 2, 14, 40, 35, 0, 37, 4, 36, 13, 20, 25, 24, 27, 37, 24, 37, 36, 42, 37, 37, 36, 14, 16, 43, 37, 14, 43, 35, 43, 41, 22, 43, 11, 5, 24, 10, 43, 16, 24, 37, 11, 24, 36, 18, 41, 16, 15, 36, 43, 16, 11, 0, 37, 33, 19, 37, 37, 0, 40, 43, 12, 36, 10, 37, 18, 12, 0, 39, 43, 0, 40, 3, 38, 12, 36, 15, 43, 41, 11, 16, 15, 11, 36, 47, 45, 36, 15, 0, 11, 16, 36, 40, 29, 33, 43, 37, 41, 0, 40, 43, 43, 24, 40, 24, 36, 13, 15, 43, 43, 24, 0, 47, 41, 37, 12, 18, 11, 37, 13, 41, 35, 41, 13, 36, 37, 36, 4, 41, 25, 35, 40, 6, 0, 26, 37, 40, 0, 14, 15, 36, 22, 16, 36, 43, 15, 24, 14, 14, 36, 0, 37, 16, 12, 40, 16, 13, 16, 1, 36, 43, 43, 43, 22, 13, 14, 12, 18, 5, 36, 43, 16, 37, 43, 43, 37, 37, 0, 36, 19, 13, 15, 0, 47, 24, 37, 20, 4, 4, 18, 36, 43, 12, 36, 0, 36, 40, 24, 47, 37, 47, 36, 0, 37, 24, 47, 34, 4, 36, 38, 13, 47, 6, 40, 0, 29, 22, 14, 37, 40, 43, 24, 43, 12, 41, 3, 41, 42, 16, 47, 39, 40, 12, 18, 43, 16, 43, 36, 36, 41, 11, 37, 14, 32, 43, 41, 36, 40, 13, 47, 13, 40, 43, 41, 43, 36, 37, 37, 37, 24, 12, 3, 27, 36, 16, 0, 36, 0, 47, 42, 5, 13, 15, 36, 43, 43, 24, 22, 16, 11, 36, 43, 36, 13, 38, 43, 13, 30, 35, 11, 38, 0, 4, 10, 12, 16, 14, 16, 12, 47, 43, 43, 36, 37, 0, 37, 14, 14, 0, 14, 37, 47, 13, 40, 14, 0, 42, 43, 37, 24, 47, 12, 14, 0, 42, 33, 43, 24, 6, 14, 14, 36, 43, 40, 43, 25, 13, 16, 18, 37, 36, 38, 37, 6, 38, 12, 0, 36, 4, 43, 28, 22, 43, 18, 41, 38, 15, 24, 19, 43, 40, 36, 36, 10, 24, 38, 1, 43, 12, 10, 36, 4, 0, 18, 24, 4, 15, 36, 42, 11, 43, 13, 14, 43, 5, 43, 14, 38, 24, 11, 4, 47, 43, 36, 36, 43, 6, 13, 36, 43, 36, 36, 43, 36, 6, 13, 43, 47, 0, 0, 11, 32, 40, 36, 43, 6, 38, 43, 24, 16, 43, 37, 16, 14, 15, 37, 15, 0, 42, 47, 36, 0, 14, 12, 37, 36, 41, 38, 12, 43, 36, 16, 22, 16, 13, 13, 0, 40, 4, 4, 13, 6, 22, 40, 40, 14, 36, 41, 37, 0, 19, 14, 6, 15, 12, 38, 37, 15, 36, 4, 43, 41, 43, 6, 16, 14, 15, 20, 2, 41, 19, 16, 36, 0, 1, 18, 36, 6, 15, 13, 37, 18, 0, 18, 43, 43, 47, 47, 16, 47, 12, 45, 45, 41, 40, 16, 13, 46, 15, 4, 43, 14, 16, 47, 43, 0, 32, 47, 43, 25, 36, 43, 4, 2, 41, 13, 28, 41, 43, 45, 37, 43, 43, 3, 40, 0, 14, 37, 12, 42, 24, 16, 37, 37, 12, 37, 37, 24, 14, 43, 7, 37, 42, 38, 0, 36, 40, 35, 14, 47, 47, 24, 5, 18, 0, 43, 2, 43, 0, 40, 38, 43, 47, 43, 36, 24, 35, 12, 16, 37, 40, 36, 0, 40, 13, 36, 36, 10, 6, 12, 43, 13, 13, 37, 43, 14, 43, 3, 36, 1, 39, 43, 38, 4, 18, 40, 43, 37, 47, 43, 0, 15, 42, 37, 37, 14, 40, 33, 24, 20, 0, 37, 43, 47, 24, 5, 37, 6, 3, 5, 36, 24, 4, 15, 36, 13, 25, 12, 16, 26, 43, 3, 43, 40, 36, 43, 5, 4, 45, 9, 0, 6, 16, 2, 13, 5, 36, 2, 16, 38, 14, 36, 47, 12, 47, 15, 10, 35, 4, 45, 43, 0, 36, 6, 15, 36, 43, 36, 22, 37, 10, 13, 36, 13, 12, 24, 13, 37, 13, 0, 34, 36, 43, 22, 32, 0, 36, 35, 7, 14, 40, 37, 37, 43, 14, 15, 12, 43, 45, 37, 1, 0, 37, 36, 22, 43, 43, 37, 1, 47, 42, 43, 41, 37, 6, 47, 36, 35, 0, 38, 11, 14, 45, 42, 37, 36, 38, 7, 41, 40, 36, 16, 24, 13, 47, 16, 0, 3, 43, 11, 25, 24, 12, 16, 36, 0, 25, 13, 40, 15, 37, 16, 40, 0, 13, 14, 43, 36, 43, 43, 0, 40, 37, 3, 37, 43, 13, 36, 37, 37, 2, 43, 0, 37, 40, 35, 42, 43, 0, 43, 15, 0, 37, 36, 0, 42, 13, 41, 43, 41, 3, 37, 42, 43, 15, 36, 36, 15, 43, 8, 0, 24, 18, 43, 13, 14, 13, 12, 14, 37, 40, 12, 20, 24, 43, 40, 47, 4, 36, 38, 40, 36, 14, 24, 6, 36, 12, 38, 34, 0, 4, 11, 43, 37, 36, 13, 21, 16, 40, 40, 40, 10, 43, 20, 14, 14, 43, 43, 0, 12, 13, 16, 24, 36, 22, 11, 42, 36, 37, 12, 36, 14, 13, 43, 36, 22, 19, 36, 14, 4, 13, 17, 37, 16, 36, 16, 43, 47, 36, 24, 13, 14, 43, 0, 36, 37, 36, 13, 0, 6, 0, 12, 22, 27, 24, 14, 35, 35, 43, 3, 14, 16, 13, 18, 46, 35, 0, 36, 40, 20, 37, 4, 15, 10, 0, 0, 36, 19, 0, 41, 36, 43, 41, 15, 18, 40, 36, 6, 20, 36, 13, 16, 43, 43, 37, 37, 16, 6, 43, 43, 41, 16, 36, 37, 37, 37, 22, 8, 40, 47, 13, 37, 14, 43, 4, 13, 7, 37, 4, 40, 13, 16, 37, 13, 11, 20, 16, 36, 15, 43, 36, 0, 14, 36, 43, 38, 0, 0, 35, 24, 16, 13, 36, 37, 0, 36, 3, 36, 37, 0, 35, 12, 19, 40, 42, 36, 6, 11, 22, 36, 41, 0, 37, 38, 14, 42, 46, 43, 41, 43, 14, 35, 36, 36, 12, 29, 16, 25, 35, 40, 9, 0, 4, 42, 15, 37, 16, 22, 0, 24, 24, 47, 43, 0, 14, 9, 6, 37, 12, 36, 41, 37, 36, 41, 0, 36, 4, 37, 9, 37, 14, 19, 42, 40, 24, 7, 24, 0, 12, 43, 37, 35, 37, 31, 13, 12, 16, 42, 36, 0, 0, 4, 14, 25, 14, 14, 14, 35, 13, 37, 36, 16, 43, 36, 22, 47, 14, 0, 12, 38, 15, 38, 16, 43, 45, 36, 18, 28, 12, 13, 6, 22, 15, 40, 41, 40, 15, 35, 40, 25, 36, 0, 43, 36, 21, 25, 26, 26, 0, 14, 43, 13, 36, 36, 24, 14, 37, 43, 37, 36, 24, 13, 16, 16, 24, 43, 47, 24, 34, 11, 0, 15, 37, 0, 36, 47, 16, 40, 4, 38, 36, 36, 36, 36, 15, 18, 16, 24, 20, 16, 40, 43, 0, 43, 37, 6, 43, 38, 11, 2, 0, 37, 22, 18, 36, 37, 0, 13, 10, 43, 40, 47, 14, 12, 37, 41, 47, 24, 16, 22, 36, 36, 14, 14, 40, 0, 12, 21, 43, 36, 42, 34, 40, 37, 36, 16, 15, 18, 38, 43, 36, 12, 0, 0, 0, 43, 36, 14, 6, 6, 29, 14, 4, 36, 45, 37, 37, 37, 37, 39, 24, 43, 36, 36, 36, 35, 40, 16, 14, 13, 36, 22, 40, 15, 43, 22, 16, 47, 36, 35, 4, 24, 6, 30, 24, 0, 24, 14, 14, 0, 6, 36, 21, 41, 14, 36, 22, 40, 41, 43, 36, 13, 15, 12, 0, 13, 16, 16, 37, 27, 37, 6, 1, 24, 24, 0, 37, 14, 36, 1, 31, 12, 13, 13, 36, 14, 43, 16, 13, 36, 43, 0, 20, 36, 36, 43, 20, 43, 47, 22, 20, 3, 43, 36, 38, 12, 7, 37, 12, 38, 13, 34, 11, 36, 2, 40, 0, 24, 40, 12, 47, 13, 24, 14, 6, 13, 36, 41, 47, 43, 39, 3, 12, 14, 36, 15, 43, 43, 18, 0, 21, 37, 36, 6, 14, 14, 40, 45, 40, 16, 7, 37, 24, 43, 37, 36, 41, 47, 4, 33, 43, 41, 7, 43, 36, 13, 6, 33, 43, 0, 36, 47, 0, 38, 0, 41, 0, 6, 42, 43, 45, 43, 43, 35, 43, 4, 43, 43, 12, 24, 36, 22, 0, 40, 13, 6, 41, 14, 43, 36, 42, 6, 20, 40, 6, 0, 47, 43, 25, 42, 41, 43, 37, 14, 33, 19, 47, 37, 12, 15, 37, 13, 37, 40, 41, 16, 36, 26, 2, 37, 43, 37, 14, 36, 43, 37, 16, 12, 47, 13, 38, 33, 42, 36, 40, 47, 45, 16, 20, 3, 14, 13, 12, 37, 37, 22, 13, 38, 43, 43, 14, 15, 47, 30, 36, 6, 18, 22, 15, 43, 40, 47, 24, 16, 41, 0, 12, 40, 0, 35, 46, 36, 36, 36, 40, 17, 36, 37, 37, 36, 6, 36, 14, 43, 16, 43, 41, 6, 36, 22, 2, 6, 36, 12, 15, 14, 5, 37, 4, 30, 43, 37, 24, 43, 2, 10, 42, 13, 0, 20, 34, 6, 15, 40, 36, 12, 24, 14, 36, 2, 36, 24, 43, 13, 6, 13, 13, 13, 12, 40, 36, 14, 37, 14, 43, 36, 41, 45, 37, 38, 0, 11, 41, 1, 13, 6, 30, 12, 38, 36, 42, 37, 13, 13, 40, 37, 43, 24, 11, 37, 14, 0, 36, 43, 12, 43, 47, 40, 13, 33, 40, 37, 13, 6, 15, 14, 36, 36, 36, 14, 11, 47, 13, 13, 39, 41, 6, 36, 37, 27, 15, 33, 38, 0, 45, 14, 28, 14, 20, 40, 38, 13, 38, 0, 42, 40, 37, 43, 0, 22, 47, 43, 41, 43, 43, 16, 24, 36, 40, 16, 0, 37, 9, 43, 7, 5, 6, 15, 14, 11, 40, 6, 47, 43, 14, 43, 13, 6, 34, 24, 4, 40, 26, 43, 0, 40, 36, 21, 25, 14, 13, 43, 24, 47, 43, 40, 13, 0, 41, 14, 40, 7, 41, 40, 16, 6, 36, 35, 20, 4, 40, 16, 43, 45, 36, 26, 3, 43, 24, 4, 37, 5, 43, 41, 36, 14, 25, 36, 4, 43, 43, 36, 43, 40, 14, 0, 47, 14, 10, 16, 12, 0, 0, 36, 11, 43, 41, 0, 2, 43, 40, 37, 12, 20, 42, 16, 13, 16, 11, 13, 40, 12, 24, 0, 43, 37, 15, 24, 39, 45, 43, 0, 16, 24, 0, 6, 15, 36, 2, 41, 13, 0, 43, 16, 14, 6, 1, 36, 0, 37, 43, 36, 40, 43, 0, 36, 16, 16, 9, 36, 4, 40, 14, 11, 19, 42, 6, 36, 22, 12, 37, 14, 14, 12, 24, 24, 16, 43, 43, 0, 4, 43, 14, 14, 41, 40, 14, 10, 14, 37, 13, 36, 36, 47, 35, 45, 22, 0, 14, 36, 13, 36, 16, 6, 45, 37, 37, 35, 14, 35, 12, 40, 36, 46, 7, 36, 16, 14, 37, 43, 24, 43, 43, 20, 4, 31, 24, 36, 18, 39, 37, 46, 14, 15, 16, 12, 0, 15, 37, 13, 36, 14, 22, 13, 36, 37, 36, 38, 13, 14, 14, 11, 43, 9, 16, 0, 6, 14, 24, 42, 13, 4, 14, 43, 36, 36, 18, 37, 0, 13, 24, 43, 37, 35, 16, 41, 13, 13, 43, 37, 24, 6, 14, 36, 12, 35, 45, 17, 3, 43, 35, 36, 28, 36, 12, 35, 36, 14, 38, 19, 19, 33, 7, 0, 24, 36, 4, 31, 13, 16, 47, 47, 43, 43, 37, 13, 13, 14, 13, 36, 14, 36, 14, 37, 43, 40, 24, 6, 16, 13, 35, 36, 12, 16, 0, 22, 37, 16, 36, 14, 37, 22, 36, 18, 47, 43, 0, 43, 3, 37, 18, 40, 36, 40, 16, 11, 13, 12, 38, 35, 43, 37, 10, 43, 40, 12, 13, 6, 36, 2, 11, 9, 18, 37, 14, 16, 4, 26, 37, 12, 43, 36, 43, 13, 13, 14, 17, 42, 47, 12, 13, 13, 0, 11, 41, 14, 17, 22, 16, 38, 37, 40, 36, 37, 47, 40, 37, 41, 43, 14, 43, 43, 22, 13, 36, 37, 40, 47, 20, 12, 13, 13, 16, 36, 41, 41, 35, 0, 36, 40, 3, 25, 14, 18, 31, 43, 0, 40, 10, 30, 4, 12, 37, 20, 36, 42, 36, 15, 18, 7, 37, 0, 35, 37, 12, 34, 1, 24, 13, 24, 7, 43, 14, 46, 35, 43, 14, 40, 24, 42, 43, 40, 37, 16, 7, 6, 14, 43, 15, 40, 40, 43, 22, 15, 16, 36, 12, 36, 40, 14, 37, 47, 16, 16, 14, 36, 37, 14, 16, 20, 37, 24, 43, 37, 2, 47, 37, 0, 0, 40, 47, 36, 14, 37, 40, 36, 0, 16, 45, 14, 36, 43, 20, 4, 30, 47, 43, 36, 20, 0, 43, 22, 25, 43, 37, 37, 6, 36, 2, 43, 39, 37, 22, 37, 37, 29, 36, 0, 42, 43, 14, 43, 37, 26, 14, 24, 11, 11, 11, 43, 13, 31, 9, 0, 12, 12, 16, 6, 28, 40, 43, 10, 13, 35, 36, 36, 14, 37, 47, 6, 37, 36, 37, 35, 11, 41, 43, 36, 18, 0, 40, 4, 43, 43, 40, 36, 47, 13, 15, 4, 43, 0, 47, 14, 42, 36, 43, 10, 43, 43, 40, 15, 14, 0, 40, 12, 41, 37, 22, 16, 16, 12, 14, 16, 19, 23, 36, 14, 19, 3, 14, 37, 43, 16, 14, 47, 43, 0, 15, 18, 35, 13, 23, 47, 38, 43, 24, 0, 37, 33, 22, 11, 13, 37, 40, 46, 12, 15, 16, 43, 19, 14, 36, 4, 12, 10, 40, 11, 24, 2, 36, 15, 22, 46, 47, 42, 37, 36, 10, 24, 40, 42, 0, 18, 43, 4, 0, 43, 36, 13, 43, 24, 12, 36, 30, 16, 16, 24, 47, 41, 40, 39, 15, 25, 43, 7, 37, 16, 13, 36, 18, 43, 43, 40, 43, 30, 22, 0, 18, 15, 5, 1, 3, 16, 16, 16, 47, 37, 40, 42, 37, 42, 36, 18, 35, 7, 13, 22, 41, 43, 19, 41, 0, 15, 0, 4, 0, 42, 40, 37, 13, 30, 41, 41, 14, 41, 16, 37, 11, 43, 24, 24, 43, 36, 12, 36, 12, 36, 0, 16, 37, 37, 41, 36, 38, 0, 0, 13, 37, 12, 42, 12, 11, 11, 16, 13, 20, 37, 43, 22, 36, 37, 6, 41, 14, 4, 42, 14, 37, 36, 27, 43, 13, 41, 41, 40, 14, 47, 19, 36, 14, 14, 14, 36, 43, 11, 37, 12, 14, 35, 0, 16, 37, 36, 20, 20, 35, 34, 7, 27, 7, 43, 0, 42, 2, 12, 9, 27, 43, 43, 43, 47, 4, 12, 43, 36, 16, 6, 38, 42, 36, 45, 43, 12, 47, 3, 0, 43, 13, 16, 4, 22, 38, 36, 37, 47, 24, 40, 37, 14, 42, 41, 20, 13, 36, 37, 43, 43, 30, 45, 43, 15, 40, 15, 13, 13, 24, 3, 11, 13, 19, 41, 42, 33, 22, 41, 22, 36, 24, 36, 27, 43, 43, 37, 6, 12, 36, 12, 11, 18, 36, 47, 37, 1, 13, 43, 15, 43, 7, 1, 24, 12, 18, 15, 18, 36, 4, 37, 13, 37, 16, 37, 43, 38, 43, 0, 0, 43, 6, 43, 14, 7, 14, 6, 42, 43, 36, 36, 36, 36, 12, 24, 24, 5, 16, 10, 28, 41, 37, 15, 16, 22, 37, 43, 47, 10, 11, 36, 41, 41, 43, 35, 12, 14, 7, 40, 16, 0, 37, 0, 41, 14, 6, 24, 42, 5, 43, 38, 40, 43, 0, 37, 41, 20, 24, 6, 40, 13, 14, 36, 40, 6, 8, 24, 36, 14, 14, 3, 37, 4, 24, 0, 16, 36, 43, 42, 43, 0, 28, 11, 14, 3, 13, 42, 43, 13, 15, 41, 36, 20, 0, 36, 15, 36, 36, 40, 18, 22, 36, 41, 37, 33, 0, 40, 37, 37, 37, 14, 13, 0, 36, 36, 33, 24, 47, 36, 41, 24, 43, 14, 3, 36, 37, 38, 43, 0, 11, 0, 37, 37, 6, 12, 42, 36, 37, 13, 43, 12, 16, 20, 36, 40, 4, 12, 43, 38, 33, 11, 37, 37, 37, 36, 10, 43, 36, 43, 43, 16, 24, 5, 14, 43, 5, 13, 6, 14, 15, 12, 0, 43, 36, 24, 11, 43, 13, 40, 13, 4, 41, 33, 43, 28, 12, 36, 37, 4, 6, 41, 15, 37, 47, 12, 40, 11, 36, 11, 12, 47, 43, 0, 41, 47, 16, 14, 6, 4, 19, 41, 36, 40, 0, 37, 41, 43, 30, 0, 0, 43, 38, 37, 42, 19, 37, 6, 40, 0, 37, 20, 25, 37, 6, 14, 4, 16, 16, 15, 0, 37, 43, 19, 43, 12, 40, 43, 43, 34, 12, 9, 37, 42, 16, 41, 14, 36, 37, 37, 35, 16, 39, 47, 18, 19, 16, 0, 6, 36, 43, 25, 37, 15, 6, 47, 0, 12, 43, 25, 40, 16, 0, 40, 43, 3, 47, 10, 43, 6, 36, 40, 22, 36, 19, 40, 42, 16, 0, 16, 37, 12, 0, 16, 11, 25, 43, 41, 12, 42, 15, 40, 43, 14, 37, 40, 24, 13, 37, 13, 43, 0, 36, 25, 37, 43, 24, 4, 36, 42, 40, 43, 37, 47, 43, 0, 24, 16, 11, 7, 19, 43, 33, 24, 15, 12, 36, 9, 0, 43, 43, 4, 37, 42, 37, 15, 37, 7, 9, 40, 36, 37, 43, 36, 47, 37, 36, 37, 9, 16, 15, 3, 4, 47, 41, 30, 19, 30, 12, 16, 3, 0, 36, 43, 33, 18, 31, 31, 24, 24, 40, 16, 35, 16, 36, 15, 18, 36, 37, 40, 5, 14, 36, 36, 43, 36, 6, 43, 16, 43, 36, 6, 6, 36, 14, 46, 13, 37, 40, 7, 10, 24, 41, 16, 35, 8, 46, 16, 16, 12, 0, 42, 6, 41, 25, 0, 7, 36, 14, 37, 36, 13, 38, 37, 43, 12, 47, 43, 35, 41, 35, 0, 41, 0, 19, 16, 11, 20, 16, 13, 40, 37, 15, 6, 40, 36, 37, 47, 14, 41, 40, 14, 24, 36, 16, 6, 22, 33, 11, 1, 13, 13, 43, 12, 40, 14, 46, 12, 43, 14, 43, 43, 3, 14, 43, 14, 37, 15, 16, 12, 16, 37, 43, 15, 14, 14, 18, 37, 33, 37, 0, 37, 41, 36, 15, 13, 15, 0, 3, 37, 36, 38, 36, 37, 16, 4, 6, 0, 47, 43, 13, 43, 36, 47, 43, 0, 21, 43, 16, 14, 39, 12, 40, 47, 12, 14, 36, 43, 36, 37, 12, 37, 18, 16, 36, 5, 15, 43, 43, 0, 0, 26, 20, 41, 43, 36, 47, 3, 36, 47, 43, 41, 45, 37, 17, 43, 41, 9, 21, 14, 16, 14, 13, 16, 16, 37, 37, 10, 16, 13, 14, 11, 14, 16, 35, 36, 43, 35, 11, 4, 30, 0, 15, 15, 37, 43, 36, 13, 42, 12, 22, 24, 43, 40, 43, 40, 37, 3, 34, 43, 40, 43, 11, 35, 12, 4, 16, 36, 0, 39, 36, 22, 43, 0, 22, 14, 0, 36, 42, 6, 36, 41, 36, 6, 14, 43, 15, 16, 40, 43, 0, 35, 0, 3, 4, 16, 13, 38, 12, 0, 38, 16, 43, 37, 43, 16, 16, 43, 37, 5, 36, 36, 40, 10, 18, 43, 38, 24, 9, 47, 40, 16, 40, 4, 36, 15, 12, 6, 37, 20, 26, 43, 36, 12, 11, 20, 47, 18, 37, 13, 43, 35, 6, 0, 15, 11, 37, 47, 11, 35, 16, 38, 18, 4, 42, 36, 43, 42, 36, 47, 47, 14, 36, 12, 24, 43, 16, 37, 12, 15, 36, 11, 22, 33, 16, 40, 14, 11, 26, 43, 40, 41, 41, 15, 4, 24, 0, 12, 14, 36, 47, 4, 40, 10, 37, 43, 41, 36, 14, 36, 37, 0, 37, 11, 24, 14, 0, 24, 15, 37, 13, 37, 47, 43, 16, 15, 36, 16, 41, 40, 35, 11, 13, 24, 43, 38, 37, 0, 13, 12, 38, 30, 15, 24, 4, 43, 36, 40, 43, 36, 13, 47, 11, 16, 22, 24, 6, 14, 6, 43, 36, 37, 14, 35, 37, 25, 0, 22, 6, 36, 40, 36, 37, 24, 37, 14, 37, 40, 24, 16, 24, 10, 42, 4, 4, 35, 47, 41, 0, 43, 18, 14, 14, 13, 18, 6, 13, 38, 43, 37, 32, 36, 37, 14, 16, 42, 13, 13, 43, 22, 10, 6, 43, 22, 24, 43, 40, 0, 37, 11, 14, 14, 36, 41, 43, 36, 36, 24, 47, 43, 0, 19, 40, 15, 0, 6, 13, 22, 0, 42, 6, 42, 43, 38, 6, 40, 41, 36, 2, 37, 9, 46, 36, 3, 36, 36, 37, 37, 14, 37, 15, 24, 10, 42, 43, 36, 16, 30, 43, 16, 11, 36, 43, 24, 43, 24, 15, 36, 3, 36, 11, 36, 43, 35, 12, 40, 12, 37, 12, 37, 13, 42, 15, 13, 47, 11, 13, 43, 47, 47, 16, 6, 43, 12, 13, 43, 36, 39, 11, 43, 41, 0, 14, 16, 14, 39, 11, 38, 37, 43, 34, 13, 41, 36, 14, 6, 43, 16, 0, 13, 36, 42, 12, 24, 15, 36, 34, 36, 12, 47, 0, 16, 43, 3, 40, 43, 35, 37, 40, 43, 12, 40, 15, 13, 12, 43, 43, 28, 41, 12, 35, 0, 15, 14, 15, 0, 0, 40, 41, 1, 13, 37, 20, 40, 43, 11, 6, 36, 36, 37, 16, 0, 13, 15, 17, 4, 42, 23, 20, 47, 0, 0, 32, 42, 14, 39, 35, 25, 0, 12, 22, 36, 13, 37, 47, 43, 22, 36, 37, 36, 40, 15, 35, 43, 9, 37, 36, 14, 47, 36, 43, 0, 16, 24, 15, 24, 0, 41, 13, 0, 14, 40, 35, 4, 13, 37, 0, 39, 14, 40, 16, 13, 16, 7, 43, 43, 6, 27, 13, 41, 8, 43, 14, 0, 36, 6, 22, 33, 38, 13, 8, 40, 37, 5, 13, 4, 0, 6, 43, 40, 43, 36, 40, 25, 15, 6, 42, 20, 40, 0, 42, 36, 37, 40, 38, 40, 7, 24, 16, 40, 3, 37, 28, 12, 36, 37, 42, 36, 36, 0, 43, 16, 5, 0, 42, 24, 36, 13, 36, 47, 40, 37, 0, 37, 37, 43, 15, 18, 14, 14, 10, 13, 5, 15, 15, 36, 7, 35, 43, 15, 42, 12, 36, 40, 16, 46, 36, 37, 12, 41, 37, 16, 37, 36, 41, 38, 41, 45, 37, 47, 36, 47, 15, 18, 36, 38, 14, 13, 40, 36, 40, 35, 37, 38, 43, 12, 42, 6, 41, 15, 40, 0, 14, 36, 15, 36, 11, 18, 41, 45, 4, 14, 26, 37, 24, 12, 14, 40, 47, 4, 43, 36, 12, 36, 40, 14, 33, 41, 40, 43, 14, 43, 14, 37, 12, 11, 1, 37, 40, 14, 13, 34, 0, 40, 4, 43, 37, 46, 24, 6, 16, 11, 37, 47, 11, 36, 3, 25, 16, 43, 41, 15, 13, 47, 9, 40, 20, 43, 12, 36, 6, 13, 24, 20, 13, 4, 30, 12, 37, 7, 36, 43, 24, 36, 1, 33, 33, 24, 24, 28, 43, 37, 36, 13, 0, 42, 3, 0, 16, 37, 0, 37, 0, 36, 43, 14, 14, 13, 43, 4, 37, 41, 36, 43, 16, 37, 42, 0, 37, 47, 38, 37, 15, 36, 16, 2, 0, 0, 43, 37, 0, 14, 40, 20, 43, 45, 40, 36, 42, 40, 43, 5, 3, 0, 35, 24, 36, 6, 36, 20, 11, 43, 47, 36, 14, 1, 37, 13, 19, 40, 41, 24, 47, 18, 36, 6, 40, 14, 19, 43, 0, 41, 36, 40, 6, 41, 14, 0, 14, 12, 10, 29, 37, 37, 17, 40, 43, 36, 47, 7, 11, 30, 37, 36, 37, 37, 43, 16, 42, 20, 40, 15, 12, 41, 43, 36, 14, 15, 24, 0, 35, 43, 13, 38, 24, 14, 13, 40, 37, 43, 40, 12, 40, 36, 14, 12, 0, 16, 41, 22, 37, 25, 47, 37, 43, 18, 32, 13, 14, 31, 37, 47, 36, 13, 39, 36, 36, 15, 36, 13, 36, 47, 6, 41, 38, 37, 6, 37, 6, 20, 19, 37, 37, 12, 3, 40, 43, 15, 20, 43, 11, 38, 40, 7, 36, 25, 37, 43, 0, 25, 43, 40, 36, 38, 38, 24, 37, 14, 14, 12, 43, 40, 22, 37, 0, 37, 15, 37, 16, 0, 46, 18, 16, 36, 43, 13, 43, 12, 16, 13, 13, 40, 38, 36, 22, 40, 0, 36, 37, 15, 8, 18, 18, 36, 36, 2, 12, 36, 40, 47, 14, 11, 36, 43, 37, 24, 0, 35, 19, 47, 12, 36, 18, 19, 12, 8, 0, 36, 12, 12, 36, 24, 40, 43, 37, 43, 24, 24, 12, 27, 43, 13, 0, 14, 31, 37, 43, 16, 16, 0, 25, 37, 37, 16, 43, 38, 35, 24, 33, 47, 0, 0, 24, 47, 43, 11, 25, 37, 14, 0, 43, 36, 43, 36, 10, 43, 41, 43, 47, 35, 6, 14, 36, 36, 6, 43, 25, 40, 16, 36, 14, 14, 36, 43, 16, 40, 43, 13, 14, 20, 14, 9, 42, 36, 6, 24, 15, 36, 46, 15, 6, 12, 0, 41, 47, 36, 47, 16, 43, 13, 0, 14, 14, 36, 35, 43, 24, 14, 16, 43, 43, 15, 14, 0, 45, 13, 38, 16, 40, 41, 22, 4, 43, 36, 6, 36, 14, 40, 36, 12, 37, 47, 33, 0, 13, 10, 43, 12, 1, 6, 41, 4, 13, 10, 5, 38, 11, 36, 4, 13, 47, 22, 41, 15, 12, 12, 15, 3, 0, 14, 37, 36, 4, 37, 47, 42, 16, 12, 26, 36, 37, 14, 11, 3, 24, 16, 40, 0, 40, 47, 15, 41, 43, 5, 6, 36, 15, 36, 37, 36, 13, 18, 41, 14, 36, 36, 4, 36, 13, 36, 28, 12, 16, 13, 12, 0, 40, 47, 40, 47, 22, 15, 41, 13, 18, 36, 22, 6, 16, 24, 47, 15, 37, 13, 6, 14, 37, 43, 43, 40, 10, 36, 26, 13, 47, 33, 12, 36, 14, 36, 4, 15, 14, 4, 14, 47, 43, 43, 37, 37, 6, 0, 43, 40, 40, 38, 41, 26, 41, 16, 41, 43, 47, 47, 16, 37, 43, 35, 43, 3, 37, 22, 15, 37, 15, 43, 37, 24, 46, 25, 37, 15, 37, 36, 14, 14, 36, 47, 15, 36, 6, 40, 0, 14, 42, 37, 16, 12, 47, 43, 14, 14, 1, 12, 39, 22, 24, 0, 47, 38, 40, 42, 37, 14, 22, 6, 37, 14, 5, 38, 28, 43, 26, 15, 35, 0, 47, 36, 47, 40, 3, 27, 37, 43, 43, 40, 37, 37, 14, 3, 0, 12, 22, 36, 16, 0, 41, 40, 16, 36, 36, 43, 35, 38, 14, 37, 43, 36, 37, 15, 46, 24, 0, 36, 47, 40, 37, 41, 4, 26, 0, 24, 14, 14, 43, 15, 6, 36, 14, 11, 43, 6, 43, 47, 18, 13, 14, 14, 37, 36, 15, 4, 40, 40, 0, 37, 43, 7, 24, 12, 37, 4, 43, 4, 18, 42, 6, 37, 38, 14, 40, 43, 47, 12, 36, 13, 0, 36, 43, 37, 24, 43, 13, 13, 43, 36, 21, 4, 25, 4, 43, 40, 15, 12, 16, 20, 15, 19, 36, 13, 13, 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ov8-yJMZnJDk",
        "outputId": "bb5f9f8c-ad1e-4695-9578-d2d2064edb19"
      },
      "source": [
        "logging.basicConfig(level=logging.DEBUG,\n",
        "                    format='%(asctime)s %(message)s',\n",
        "                    handlers=[logging.FileHandler(\"ann_test.log\"),\n",
        "                              logging.StreamHandler()])\n",
        "\n",
        "p_cross = 0.5\n",
        "p_mut = 0.3\n",
        "num_parents = 10\n",
        "# num_of_crossovers_per_parent = 3\n",
        "population = 30\n",
        "epochs = 50\n",
        "epochs_per_nn = 1\n",
        "\n",
        "class ANN(Sequential):\n",
        "    \n",
        "    def __init__(self, child_weights=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fitness = 0\n",
        "        if child_weights is None:\n",
        "            layer1 = Dense(200, input_shape=(144,), activation='relu')\n",
        "            layer2 = Dense(48, activation=None)\n",
        "            self.add(layer1)\n",
        "            self.add(layer2)\n",
        "\n",
        "    def forward_propagation(self, train_feature, train_label):\n",
        "        predict_label = self.predict(train_feature)\n",
        "\n",
        "def crossover(nn1, nn2):\n",
        "    global p_cross , symp_train_data  , train_outputs\n",
        "    nn1_weights = []\n",
        "    nn2_weights = []\n",
        "    child_weights = []\n",
        "\n",
        "    for layer in nn1.layers:\n",
        "        nn1_weights.append(layer.get_weights()[0])\n",
        "    # print(len(nn1_weights[1]))\n",
        "    for layer in nn2.layers:\n",
        "        nn2_weights.append(layer.get_weights()[0])\n",
        "\n",
        "    for i in range(len(nn1_weights)):\n",
        "        # Get single point to split the matrix in parents based on # of cols\n",
        "        # split = random.randint(0, np.shape(nn1_weights[i])[1]-1)\n",
        "        # # Iterate through after a single point and set the remaing cols to nn_2\n",
        "        # for j in range(split, np.shape(nn1_weights[i])[1]-1):\n",
        "        #     nn1_weights[i][:, j] = nn2_weights[i][:, j]\n",
        "        for j in range(len(np.shape(nn1_weights[i]))):\n",
        "            cross = random.random()         #uniform crossover\n",
        "            if cross<p_cross:\n",
        "                nn1_weights[i][j] = nn2_weights[i][j];\n",
        "       \n",
        "        child_weights.append(nn1_weights[i])\n",
        "\n",
        "    mutation(child_weights)\n",
        "    final_child_weights=nn1.get_weights()\n",
        "\n",
        "    final_child_weights[0] = child_weights[0]\n",
        "    final_child_weights[2] = child_weights[1]\n",
        "    \n",
        "    child = ANN()\n",
        "    child.set_weights(final_child_weights)\n",
        "    \n",
        "    predict_label =  child.predict(symp_train_data)\n",
        "    preds_classes = np.argmax(predict_label, axis=-1)\n",
        "    child.fitness = accuracy_score(train_outputs, preds_classes)\n",
        "    print(\"Fitness of the child is \",str(child.fitness))\n",
        "    return child\n",
        "\n",
        "def mutation(child_weights):\n",
        "    global p_mut\n",
        "    for i in range(len(child_weights)):\n",
        "    # selection = random.randint(0, len(child_weights)-1)\n",
        "        mut = random.random()\n",
        "        if mut <= p_mut:\n",
        "            child_weights[i] *= random.uniform(0.7,1.3)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "# # train feature\n",
        "# train_feature = x_train.to_numpy()\n",
        "# # train label\n",
        "# train_label = y_train\n",
        "# # test feature\n",
        "# test_feature = x_test.to_numpy()\n",
        "# # test label\n",
        "# test_label = y_test\n",
        "\n",
        "# store all active ANNs\n",
        "networks = []\n",
        "pool = []\n",
        "# Generation counter\n",
        "generation = 0\n",
        "# Initial Population\n",
        "\n",
        "for i in range(population):\n",
        "    pool.append(ANN())\n",
        "# Track Max Fitness\n",
        "max_fitness = 0\n",
        "# Store Max Fitness Weights\n",
        "optimal_weights = []\n",
        "next_gen_confirmed = []\n",
        "fitness_per_generation = []\n",
        "best_model = ANN()\n",
        "# Evolution Loop\n",
        "for i in range(epochs):\n",
        "    generation += 1\n",
        "    logging.debug(\"Generation: \" + str(generation) + \"\\r\\n\")\n",
        "    z=0\n",
        "    # print(len(networks))\n",
        "    networks = []\n",
        "    for ann in pool:\n",
        "        # print(z)\n",
        "        # z+=1\n",
        "        # Propagate to calculate fitness score\n",
        "        ann.compile(optimizer=optimizers.Adam(), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # default from_logits=False\n",
        "                    metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "        ann.fit(x=symp_train_data, y = train_outputs , epochs = epochs_per_nn, verbose=0)\n",
        "        predict_label =  ann.predict(symp_train_data,)\n",
        "        preds_classes = np.argmax(predict_label, axis=-1)\n",
        "        ann.fitness = accuracy_score(train_outputs, preds_classes)\n",
        "        # Add to pool after calculating fitness\n",
        "        networks.append(ann)\n",
        "\n",
        "    # # Clear for propagation of next children\n",
        "    # # networks.clear()\n",
        "    pool = networks\n",
        "    # Sort anns by fitness\n",
        "    pool+= next_gen_confirmed\n",
        "    pool = sorted(pool, key=lambda x: x.fitness)\n",
        "    pool.reverse()\n",
        "\n",
        "    pool = pool[:population]\n",
        "\n",
        "    next_gen_confirmed = pool[:3]\n",
        "    # Find Max Fitness and Log Associated Weights\n",
        "    # for i in range(len(pool)):\n",
        "    fitness_per_generation.append(pool[0].fitness)\n",
        "\n",
        "    logging.debug(\"Max Fitness of generation : \" + str(pool[0].fitness) + \"\\r\\n\")\n",
        "    # logging.debug(\"Max Fitness of generation from back  : \" + str(pool[len(pool)-1].fitness) + \"\\r\\n\")\n",
        "    if pool[0].fitness > max_fitness:\n",
        "        max_fitness = pool[0].fitness\n",
        "\n",
        "        logging.debug(\"Max Fitness: \" + str(max_fitness) + \"\\r\\n\")\n",
        "\n",
        "        # Iterate through layers, get weights, and append to optimal\n",
        "        # optimal_weights = []\n",
        "        # for layer in pool[0].layers:\n",
        "        #     optimal_weights.append(layer.get_weights()[0])\n",
        "        # logging.debug('optimal_weights: ' + str(optimal_weights)+\"\\r\\n\")\n",
        "\n",
        "        best_model = pool[0]\n",
        "    child = []\n",
        "    # Crossover: top 5 randomly select 2 partners\n",
        "    for i in range(num_parents):\n",
        "        # for j in range(num_of_crossovers_per_parent):\n",
        "            # Create a child and add to networks\n",
        "        target = (i+1) % num_parents\n",
        "        temp = crossover(pool[i],pool[target])\n",
        "        child.append(temp.get_weights())\n",
        "        # Add to networks to calculate fitness score next iteration\n",
        "        pool.append(temp)\n",
        "    # for i in range(num_parents-1):\n",
        "    #     comparison = np.array_equal(child[i],child[i+1])\n",
        "    #     # equal_arrays = comparison.all()\n",
        "    #     print(comparison)\n",
        "\n",
        "# Create a Genetic Neural Network with optimal initial weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:29:31,816 Generation: 1\r\n",
            "\n",
            "2021-04-16 17:29:56,920 Max Fitness of generation : 0.883795187592656\n",
            "\n",
            "2021-04-16 17:29:56,921 Max Fitness: 0.883795187592656\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.883795187592656\n",
            "Fitness of the child is  0.8836811495039343\n",
            "Fitness of the child is  0.8836811495039343\n",
            "Fitness of the child is  0.883453073326491\n",
            "Fitness of the child is  0.8825407686167179\n",
            "Fitness of the child is  0.8829969209716045\n",
            "Fitness of the child is  0.8829969209716045\n",
            "Fitness of the child is  0.8829969209716045\n",
            "Fitness of the child is  0.8817425019956665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:30:00,601 Generation: 2\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8835671114152127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:30:34,426 Max Fitness of generation : 0.885961911278367\r\n",
            "\n",
            "2021-04-16 17:30:34,427 Max Fitness: 0.885961911278367\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8852776827460371\n",
            "Fitness of the child is  0.8850496065685939\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8847074923024291\n",
            "Fitness of the child is  0.8856197970122021\n",
            "Fitness of the child is  0.8847074923024291\n",
            "Fitness of the child is  0.8849355684798723\n",
            "Fitness of the child is  0.8843653780362641\n",
            "Fitness of the child is  0.8845934542137074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:30:36,829 Generation: 3\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8849355684798723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:31:11,632 Max Fitness of generation : 0.8857338351009237\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8855057589234805\n",
            "Fitness of the child is  0.8850496065685939\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8851636446573156\n",
            "Fitness of the child is  0.8851636446573156\n",
            "Fitness of the child is  0.8845934542137074\n",
            "Fitness of the child is  0.8855057589234805\n",
            "Fitness of the child is  0.8850496065685939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:31:14,099 Generation: 4\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8844794161249857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:31:49,247 Max Fitness of generation : 0.8860759493670886\r\n",
            "\n",
            "2021-04-16 17:31:49,248 Max Fitness: 0.8860759493670886\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8849355684798723\n",
            "Fitness of the child is  0.8848215303911506\n",
            "Fitness of the child is  0.8856197970122021\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8852776827460371\n",
            "Fitness of the child is  0.8855057589234805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:31:51,837 Generation: 5\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8855057589234805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:32:27,790 Max Fitness of generation : 0.8860759493670886\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8842513399475425\n",
            "Fitness of the child is  0.8856197970122021\n",
            "Fitness of the child is  0.8849355684798723\n",
            "Fitness of the child is  0.8844794161249857\n",
            "Fitness of the child is  0.8855057589234805\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8844794161249857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:32:30,362 Generation: 6\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8849355684798723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:33:06,446 Max Fitness of generation : 0.8860759493670886\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8845934542137074\n",
            "Fitness of the child is  0.8844794161249857\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8860759493670886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:33:09,097 Generation: 7\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8856197970122021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:33:45,291 Max Fitness of generation : 0.8860759493670886\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8839092256813775\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8858478731896453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:33:47,711 Generation: 8\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8849355684798723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:34:23,987 Max Fitness of generation : 0.8861899874558102\r\n",
            "\n",
            "2021-04-16 17:34:23,989 Max Fitness: 0.8861899874558102\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8856197970122021\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8857338351009237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:34:26,440 Generation: 9\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8853917208347588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:35:01,358 Max Fitness of generation : 0.8863040255445319\r\n",
            "\n",
            "2021-04-16 17:35:01,360 Max Fitness: 0.8863040255445319\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8855057589234805\n",
            "Fitness of the child is  0.8851636446573156\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8852776827460371\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8857338351009237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:35:03,937 Generation: 10\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8849355684798723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:35:40,188 Max Fitness of generation : 0.8865321017219752\r\n",
            "\n",
            "2021-04-16 17:35:40,190 Max Fitness: 0.8865321017219752\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8848215303911506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:35:42,739 Generation: 11\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8857338351009237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:36:19,295 Max Fitness of generation : 0.8863040255445319\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8853917208347588\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8847074923024291\n",
            "Fitness of the child is  0.8855057589234805\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8858478731896453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:36:22,017 Generation: 12\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8853917208347588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:36:58,907 Max Fitness of generation : 0.8864180636332535\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.8860759493670886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:37:01,514 Generation: 13\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8861899874558102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:37:38,021 Max Fitness of generation : 0.8864180636332535\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8852776827460371\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8858478731896453\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8855057589234805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:37:40,666 Generation: 14\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8850496065685939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:38:17,456 Max Fitness of generation : 0.8866461398106967\r\n",
            "\n",
            "2021-04-16 17:38:17,457 Max Fitness: 0.8866461398106967\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8856197970122021\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8860759493670886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:38:20,000 Generation: 15\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.885961911278367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:38:55,597 Max Fitness of generation : 0.8865321017219752\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8861899874558102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:38:59,129 Generation: 16\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8861899874558102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:39:34,998 Max Fitness of generation : 0.8863040255445319\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8857338351009237\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.885961911278367\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8860759493670886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:39:38,605 Generation: 17\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.885961911278367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:40:15,071 Max Fitness of generation : 0.8866461398106967\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8856197970122021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:40:17,750 Generation: 18\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8861899874558102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:40:53,388 Max Fitness of generation : 0.8865321017219752\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8856197970122021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:40:57,024 Generation: 19\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8850496065685939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:41:32,581 Max Fitness of generation : 0.8867601778994184\r\n",
            "\n",
            "2021-04-16 17:41:32,583 Max Fitness: 0.8867601778994184\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8851636446573156\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8864180636332535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:41:34,994 Generation: 20\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8865321017219752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:42:12,765 Max Fitness of generation : 0.8866461398106967\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8865321017219752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:42:15,388 Generation: 21\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.885961911278367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:42:50,475 Max Fitness of generation : 0.8866461398106967\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8863040255445319\n",
            "Fitness of the child is  0.8860759493670886\n",
            "Fitness of the child is  0.8865321017219752\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8861899874558102\n",
            "Fitness of the child is  0.8864180636332535\n",
            "Fitness of the child is  0.8861899874558102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:42:53,876 Generation: 22\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8860759493670886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:43:29,230 Max Fitness of generation : 0.8867601778994184\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8867601778994184\n",
            "Fitness of the child is  0.8867601778994184\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8866461398106967\n",
            "Fitness of the child is  0.8866461398106967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:43:31,632 Generation: 23\r\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitness of the child is  0.8866461398106967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7113fd1e43cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         ann.compile(optimizer=optimizers.Adam(), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # default from_logits=False\n\u001b[1;32m    116\u001b[0m                     metrics=[keras.metrics.SparseCategoricalAccuracy()])\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymp_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_outputs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs_per_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mpredict_label\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymp_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mpreds_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16KMagPvi3fO",
        "outputId": "67d6fe61-9360-447e-89cb-05f9456760cd"
      },
      "source": [
        "ann = ANN\n",
        "ann.set_weights(best_model.get_weights())\n",
        "predict_label =  ann.predict(symp_train_data)\n",
        "preds_classes = np.argmax(predict_label, axis=-1)\n",
        "ann.fitness = accuracy_score(train_outputs, preds_classes)\n",
        "\n",
        "print(ann.fitness)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(144, 200)\n",
            "0.0206536541080345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2MzzOpn0D1w"
      },
      "source": [
        "### Block for finding the Random Forest Models\n",
        "\n",
        "The following block need not be run again since optimal hyperparameters have been founded already.\n",
        "\n",
        "A random forest regressor has been used for the training & testing of the optimal parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Gwdh6iqnJR"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Create the parameter grid based on the results of random search \n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [30, 40, 50, 60],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_samples_split': [3, 5, 7],\n",
        "    'n_estimators': [800, 900, 1000, 1500]\n",
        "}\n",
        "\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                           scoring = 'neg_mean_absolute_error', cv = 3, \n",
        "                           n_jobs = -1, verbose = 2)\n",
        "\n",
        "grid_search.fit(x_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDTY3Mt-Ct7E"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ylma0t0hbi"
      },
      "source": [
        "### Model Training (Random Forest/ Naive Bayes)\n",
        "\n",
        "This is the Training Part of the Model using a random forest classifier. Option is available for Naive Bayes classification also."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj1DSdSXMSSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fa730b-7b9b-4032-99b0-e91599d56a67"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# For model\n",
        "# model = GaussianNB()\n",
        "model = RandomForestClassifier(n_estimators=1200, max_depth=20, min_samples_split=5, min_samples_leaf=2, max_features='sqrt', bootstrap=True)\n",
        "\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=20, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=2, min_samples_split=5,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=1200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E0I7l93MSSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "b2f25a0f-47a6-4108-c6f0-bd54614aa826"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "# y_true = le.fit_transform(df_train['prognosis'])\n",
        "y_pred=model.predict(x_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1869812ae2f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1993\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m                 \u001b[0;34m\"parameter\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m             )\n\u001b[1;32m   1997\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 21, does not match size of target_names, 5. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amr0UtY8MSS5"
      },
      "source": [
        "le.inverse_transform(model.classes_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "ez3hN4bcEwM4",
        "outputId": "07ccd2c2-d385-459f-853b-e3fc602af7fb"
      },
      "source": [
        "import pygad\n",
        "import pygad.nn\n",
        "import pygad.gann\n",
        "\n",
        "def fitness_func(solution, sol_idx):\n",
        "    global GANN_instance, data_inputs, data_outputs\n",
        "\n",
        "    predictions = pygad.nn.predict(last_layer=GANN_instance.population_networks[sol_idx],\n",
        "                                   data_inputs=data_inputs)\n",
        "    # correct_predictions = np.where(predictions == data_outputs)[0].size\n",
        "    # solution_fitness = (correct_predictions/data_outputs.size)*100\n",
        "    # predict_label =  ann(symp_train_data).detach().cpu().numpy()\n",
        "    predict_label = np.argmax(predictions, axis=-1)\n",
        "    solution_fitness = accuracy_score(data_outputs, predict_label)\n",
        "    return solution_fitness\n",
        "\n",
        "def callback_generation(ga_instance):\n",
        "    global GANN_instance\n",
        "\n",
        "    population_matrices = pygad.gann.population_as_matrices(population_networks=GANN_instance.population_networks, \n",
        "                                                            population_vectors=ga_instance.population)\n",
        "\n",
        "    GANN_instance.update_population_trained_weights(population_trained_weights=population_matrices)\n",
        "\n",
        "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "    print(\"Accuracy   = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "\n",
        "data_inputs = x_train.to_numpy()\n",
        "\n",
        "data_outputs = y_train\n",
        "\n",
        "GANN_instance = pygad.gann.GANN(num_solutions=5,\n",
        "                                num_neurons_input=144,\n",
        "                                num_neurons_hidden_layers=[200],\n",
        "                                num_neurons_output=48,\n",
        "                                hidden_activations=[\"relu\"],\n",
        "                                output_activation=\"softmax\")\n",
        "\n",
        "population_vectors = pygad.gann.population_as_vectors(population_networks=GANN_instance.population_networks)\n",
        "\n",
        "ga_instance = pygad.GA(num_generations=50, \n",
        "                       num_parents_mating=3, \n",
        "                       initial_population=population_vectors.copy(),\n",
        "                       fitness_func=fitness_func,\n",
        "                       mutation_percent_genes=5,\n",
        "                       callback_generation=callback_generation)\n",
        "\n",
        "ga_instance.run()\n",
        "\n",
        "ga_instance.plot_result()\n",
        "\n",
        "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "print(solution)\n",
        "print(solution_fitness)\n",
        "print(solution_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pygad/pygad.py:617: UserWarning: Starting from PyGAD 2.6.0, the callback_generation parameter is deprecated and will be removed in a later release of PyGAD. Please use the on_generation parameter instead.\n",
            "  if not self.suppress_warnings: warnings.warn(\"Starting from PyGAD 2.6.0, the callback_generation parameter is deprecated and will be removed in a later release of PyGAD. Please use the on_generation parameter instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation = 1\n",
            "Accuracy   = 2.9505220154334997\n",
            "Generation = 2\n",
            "Accuracy   = 2.9505220154334997\n",
            "Generation = 3\n",
            "Accuracy   = 2.9505220154334997\n",
            "Generation = 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-736821c4373a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                        callback_generation=callback_generation)\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;31m# If the callback_generation attribute is not None, then cal the callback function after the generation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_generation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                     \u001b[0;31m# Before aborting the loop, save the fitness value of the best solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-736821c4373a>\u001b[0m in \u001b[0;36mcallback_generation\u001b[0;34m(ga_instance)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generation = {generation}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations_completed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy   = {fitness}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mdata_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mbest_solution\u001b[0;34m(self, pop_fitness)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         \u001b[0;31m# At first, the fitness is calculated for each solution in the final generation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpop_fitness\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m             \u001b[0mpop_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_pop_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2213\u001b[0m         \u001b[0;31m# Then return the index of that solution corresponding to the best fitness.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m         \u001b[0mbest_match_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_fitness\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_fitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mcal_pop_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;31m# Calculating the fitness value of each solution in the current population.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m             \u001b[0mpop_fitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-736821c4373a>\u001b[0m in \u001b[0;36mfitness_func\u001b[0;34m(solution, sol_idx)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     predictions = pygad.nn.predict(last_layer=GANN_instance.population_networks[sol_idx],\n\u001b[0;32m----> 9\u001b[0;31m                                    data_inputs=data_inputs)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msolution_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect_predictions\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pygad/nn/nn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(last_layer, data_inputs, problem_type)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurr_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Nh-52mFnFI"
      },
      "source": [
        "### ANN Training\n",
        "\n",
        "Training part for an ANN classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d42L3nAuF9_8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mom-4K3x2mNV"
      },
      "source": [
        "### Loading Model\n",
        "\n",
        "Using pickle to load the saved model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihcuJLqRxeEu"
      },
      "source": [
        "import pickle # For loading the saved model\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import preprocessing # For Label Encoding\n",
        "\n",
        "file_dir = 'gdrive/My Drive/IIT Bhilai Internship/Models/SymCat Random Forest Model/'\n",
        "\n",
        "# Loading Features & Label Names\n",
        "df = pd.read_csv(file_dir + 'Training.csv')\n",
        "df_test = pd.read_csv(file_dir + 'Testing.csv')\n",
        "\n",
        "# Label Encodings\n",
        "le = preprocessing.LabelEncoder()\n",
        "arn = pd.concat([df['prognosis'], df_test['prognosis']])\n",
        "le.fit(pd.concat([df['prognosis'], df_test['prognosis']]))\n",
        "\n",
        "# Loading Model (Naive-Bayes)\n",
        "model= pickle.load(open(file_dir + 'NB_model_pickle.pkl', 'rb'))\n",
        "\n",
        "#Loading Model (Random Forest)\n",
        "# model= pickle.load(open(file_dir + 'NB_model_pickle.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV9lqo8Q2tyU"
      },
      "source": [
        "### Model Test Script\n",
        "\n",
        "The model is "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdcXRXqLqZ3P"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open((file_dir + 'RF_model_pickle.pkl'), 'wb') as f:\n",
        "  pickle.dump(model,f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}